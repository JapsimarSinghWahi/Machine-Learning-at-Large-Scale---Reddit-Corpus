{"cells":[{"cell_type":"code","source":["from collections import defaultdict\nimport numpy as np\nfrom pyspark.ml.linalg import SparseVector\nfrom pyspark.sql.functions import explode\nfrom pyspark import SparkFiles\nfrom pyspark.sql import Row\n\nimport bz2\nimport json\nimport time\nfrom pyspark.ml import Pipeline\nfrom pyspark.ml.feature import * # CountVectorizer, Tokenizer, RegexTokenizer, HashingTF\nfrom pyspark.ml.regression import * # RandomForestRegressor, LinearRegression, DecisionTreeRegressor\nfrom pyspark.ml.evaluation import RegressionEvaluator"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9e52b755-eb45-4bc7-bc6c-24d784f4e43b"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["def timeit(method):\n    '''\n    Decorator to time functions.\n    '''\n    def timed(*args, **kw):\n        ts = time.time()\n        result = method(*args, **kw)\n        te = time.time()\n\n        print('%r took %2.2f sec\\n' % (method.__name__, te-ts))\n              \n        return result\n    return timed"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"689691e4-0cf1-44e2-acb2-f1599d06c782"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["import re\n# DATAFILE_PATTERN = '^(.+),\"(.+)\",(.*),(.*),(.*)'\nID_PATTERN = '\"id\":(.*?(?=,|}))'\nUPS_PATTERN = '\"ups\":(.*?(?=,|}))'\nBODY_PATTERN = '\"body\":(.*?(?=,|}))'\n# DOWNS_PATTERN = '\"downs\":(.*?(?=,|}))'\nSCORE_PATTERN = '\"score\":(.*?(?=,|}))'\n# CONTROVERSIALITY_PATTERN = '\"controversiality\":(.*?(?=,|}))'\n\ndef removeQuotes(s):\n    \"\"\" Remove quotation marks from an input string\n    Args:\n        s (str): input string that might have the quote \"\" characters\n    Returns:\n        str: a string without the quote characters\n    \"\"\"\n    return ''.join(i for i in s if i!='\"')\n\ndef parseDatafileLine(datafileLine):\n    \"\"\" Parse a line of the data file using the specified regular expression pattern\n    Args:\n        datafileLine (str): input string that is a line from the data file\n    Returns:\n        tuple: a tuple including the parsed results using the given regular expression and without the quote characters\n    \"\"\"\n    id_match = re.search(ID_PATTERN, datafileLine.decode('utf-8'))\n    ups_match = re.search(UPS_PATTERN, datafileLine.decode('utf-8'))\n    body_match = re.search(BODY_PATTERN, datafileLine.decode('utf-8'))\n    score_match = re.search(SCORE_PATTERN, datafileLine.decode('utf-8'))\n    \n    if (id_match is None) or (ups_match is None) or (body_match is None) or (score_match is None):\n        print('Invalid datafile line: %s' % datafileLine)\n        return (datafileLine, -1)\n    else:\n        viralness = 0\n        if int(score_match.group(1)) < -10 or int(score_match.group(1)) > 10:\n            viralness = 1\n        comment = (id_match.group(1), int(ups_match.group(1)), removeQuotes(body_match.group(1)), int(score_match.group(1)), viralness)\n        return (comment, 1)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6fdc11d3-11e2-48aa-af70-67d0388ea1b4"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["import sys\nimport os\nfrom pyspark import SparkFiles\n\nRC_PATH = '/FileStore/shared_uploads/ddk1@andrew.cmu.edu/RC_2007_10'\n\ndef parseData(path):\n    \"\"\" Parse a data file\n    Args:\n        filename (str): input file name of the data file\n    Returns:\n        RDD: a RDD of parsed lines\n    \"\"\"\n#     sc.addFile(path)\n    return (sc\n            .textFile(SparkFiles.get(path), 4, 0)\n            .map(parseDatafileLine)\n            .cache())\n\ndef loadData(path):\n    \"\"\" Load a data file\n    Args:\n        path (str): input file name of the data file\n    Returns:\n        RDD: a RDD of parsed valid lines\n    \"\"\"\n\n    raw = parseData(path).cache()\n    \n    failed = (raw\n              .filter(lambda s: s[1] == -1)\n              .map(lambda s: s[0]))\n    for line in failed.take(10):\n        print('%s - Invalid datafile line: %s' % (path, line))\n    \n    deleted = (raw\n             .filter(lambda s: s[0][2] == '[deleted]')\n             .map(lambda s: s[0]))\n    \n    valid = (raw\n             .filter(lambda s: s[1] == 1)\n             .filter(lambda s: s[0][2] != '[deleted]')\n             .map(lambda s: s[0])\n             .cache())\n    viral = (raw\n             .filter(lambda s: s[1] == 1)\n             .filter(lambda s: s[0][4] == 1)\n             .map(lambda s: s[0])\n             .cache())\n    nonviral = (raw\n               .filter(lambda s: s[1] == 1)\n               .filter(lambda s: s[0][4] == 0)\n               .map(lambda s: s[0])\n               .cache())\n    nonviral_cut = nonviral.sample(False, viral.count()/nonviral.count())\n    viral_nonviral_cut = viral.union(nonviral_cut)\n    print('%s - Read %d lines, successfully parsed %d lines, failed to parse %d lines, %d lines were deleted, %d lines were viral, %d lines were non-viral, %d viral and non-viral lines were returned' % (path,\n                                                                                                                                                                                                 raw.count(),\n                                                                                                                                                                                                 valid.count(),\n                                                                                                                                                                                                 failed.count(),\n                                                                                                                                                                                                 deleted.count(),\n                                                                                                                                                                                                 viral.count(),\n                                                                                                                                                                                                 nonviral.count(),\n                                                                                                                                                                                                 viral_nonviral_cut.count()))\n    return viral_nonviral_cut\n\nreddit = loadData(RC_PATH)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2e6c9126-dc8d-4982-a4dc-8e4efeb7a24a"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">/FileStore/shared_uploads/ddk1@andrew.cmu.edu/RC_2007_10 - Read 150429 lines, successfully parsed 126320 lines, failed to parse 0 lines, 24109 lines were deleted, 13183 lines were viral, 137246 lines were non-viral, 26211 viral and non-viral lines were returned\n</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">/FileStore/shared_uploads/ddk1@andrew.cmu.edu/RC_2007_10 - Read 150429 lines, successfully parsed 126320 lines, failed to parse 0 lines, 24109 lines were deleted, 13183 lines were viral, 137246 lines were non-viral, 26211 viral and non-viral lines were returned\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["sentenceDF = reddit.toDF().selectExpr(\"_1 as id\", \"_2 as ups\", \"_3 as body\", \"_4 as score\", \"_5 as viralness\")\nsentenceDF.show(n=5)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"20db18e9-ee46-47a0-99c0-b4a2be893e6c"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+---------+---+--------------------+-----+---------+\n|       id|ups|                body|score|viralness|\n+---------+---+--------------------+-----+---------+\n|&#34;c0299b0&#34;| 12|Is anyone else&#39;s ...|   12|        1|\n|&#34;c0299b5&#34;| 12|can&#39;t see beta.re...|   12|        1|\n|&#34;c0299bv&#34;| 22|This new comment ...|   22|        1|\n|&#34;c0299ey&#34;|157|There aren&#39;t many...|  157|        1|\n|&#34;c0299fr&#34;| 20|Shouldn&#39;t you hav...|   20|        1|\n+---------+---+--------------------+-----+---------+\nonly showing top 5 rows\n\n</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+---------+---+--------------------+-----+---------+\n       id|ups|                body|score|viralness|\n+---------+---+--------------------+-----+---------+\n&#34;c0299b0&#34;| 12|Is anyone else&#39;s ...|   12|        1|\n&#34;c0299b5&#34;| 12|can&#39;t see beta.re...|   12|        1|\n&#34;c0299bv&#34;| 22|This new comment ...|   22|        1|\n&#34;c0299ey&#34;|157|There aren&#39;t many...|  157|        1|\n&#34;c0299fr&#34;| 20|Shouldn&#39;t you hav...|   20|        1|\n+---------+---+--------------------+-----+---------+\nonly showing top 5 rows\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["split_regex = r'\\W+'\nlinebreak_regex = r'\\\\r\\\\n\\\\r\\\\n'\n\ndef simpleTokenize(string):\n    \"\"\" A simple implementation of input string tokenization\n    Args:\n        string (str): input string\n    Returns:\n        list: a list of tokens\n    \"\"\"\n    linebreak_removed_string = re.sub(linebreak_regex, \" \", string)\n    return list(filter(None, re.split(split_regex, linebreak_removed_string.lower())))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f7767923-51bd-42dc-bee2-fb4215facf86"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["stopfile = \"https://raw.githubusercontent.com/10605/data/master/hw1/stopwords.txt\"\nsc.addFile(stopfile)\nstopwords = set(sc.textFile(\"file://\" + SparkFiles.get(\"stopwords.txt\")).collect())\nprint('These are the stopwords: %s' % stopwords)\n\ndef tokenize(string):\n    \"\"\" An implementation of input string tokenization that excludes stopwords\n    Args:\n        string (str): input string\n    Returns:\n        list: a list of tokens without stopwords\n    \"\"\"\n    return list(filter(lambda word: word not in stopwords,simpleTokenize(string)))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0ad71685-be7c-4bb6-b77a-20c6faf2339e"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">These are the stopwords: {&#39;out&#39;, &#39;we&#39;, &#39;was&#39;, &#39;how&#39;, &#39;myself&#39;, &#39;for&#39;, &#39;they&#39;, &#39;about&#39;, &#39;then&#39;, &#39;both&#39;, &#39;so&#39;, &#39;don&#39;, &#39;as&#39;, &#39;any&#39;, &#39;after&#39;, &#39;you&#39;, &#39;why&#39;, &#39;been&#39;, &#39;where&#39;, &#39;by&#39;, &#39;yourself&#39;, &#39;a&#39;, &#39;did&#39;, &#39;their&#39;, &#39;doing&#39;, &#39;be&#39;, &#39;further&#39;, &#39;ours&#39;, &#39;now&#39;, &#39;am&#39;, &#39;her&#39;, &#39;yourselves&#39;, &#39;that&#39;, &#39;what&#39;, &#39;my&#39;, &#39;to&#39;, &#39;not&#39;, &#39;own&#39;, &#39;there&#39;, &#39;this&#39;, &#39;each&#39;, &#39;all&#39;, &#39;more&#39;, &#39;me&#39;, &#39;which&#39;, &#39;himself&#39;, &#39;nor&#39;, &#39;other&#39;, &#39;who&#39;, &#39;same&#39;, &#39;at&#39;, &#39;such&#39;, &#39;t&#39;, &#39;up&#39;, &#39;than&#39;, &#39;can&#39;, &#39;too&#39;, &#39;these&#39;, &#39;while&#39;, &#39;before&#39;, &#39;ourselves&#39;, &#39;he&#39;, &#39;i&#39;, &#39;our&#39;, &#39;its&#39;, &#39;but&#39;, &#39;with&#39;, &#39;because&#39;, &#39;those&#39;, &#39;the&#39;, &#39;it&#39;, &#39;hers&#39;, &#39;just&#39;, &#39;over&#39;, &#39;between&#39;, &#39;had&#39;, &#39;does&#39;, &#39;have&#39;, &#39;and&#39;, &#39;some&#39;, &#39;or&#39;, &#39;only&#39;, &#39;when&#39;, &#39;below&#39;, &#39;in&#39;, &#39;if&#39;, &#39;theirs&#39;, &#39;again&#39;, &#39;his&#39;, &#39;whom&#39;, &#39;above&#39;, &#39;should&#39;, &#39;itself&#39;, &#39;themselves&#39;, &#39;until&#39;, &#39;are&#39;, &#39;she&#39;, &#39;will&#39;, &#39;from&#39;, &#39;into&#39;, &#39;no&#39;, &#39;your&#39;, &#39;few&#39;, &#39;herself&#39;, &#39;of&#39;, &#39;has&#39;, &#39;down&#39;, &#39;were&#39;, &#39;once&#39;, &#39;having&#39;, &#39;them&#39;, &#39;under&#39;, &#39;him&#39;, &#39;do&#39;, &#39;on&#39;, &#39;an&#39;, &#39;yours&#39;, &#39;being&#39;, &#39;off&#39;, &#39;very&#39;, &#39;through&#39;, &#39;most&#39;, &#39;against&#39;, &#39;here&#39;, &#39;is&#39;, &#39;s&#39;, &#39;during&#39;}\n</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">These are the stopwords: {&#39;out&#39;, &#39;we&#39;, &#39;was&#39;, &#39;how&#39;, &#39;myself&#39;, &#39;for&#39;, &#39;they&#39;, &#39;about&#39;, &#39;then&#39;, &#39;both&#39;, &#39;so&#39;, &#39;don&#39;, &#39;as&#39;, &#39;any&#39;, &#39;after&#39;, &#39;you&#39;, &#39;why&#39;, &#39;been&#39;, &#39;where&#39;, &#39;by&#39;, &#39;yourself&#39;, &#39;a&#39;, &#39;did&#39;, &#39;their&#39;, &#39;doing&#39;, &#39;be&#39;, &#39;further&#39;, &#39;ours&#39;, &#39;now&#39;, &#39;am&#39;, &#39;her&#39;, &#39;yourselves&#39;, &#39;that&#39;, &#39;what&#39;, &#39;my&#39;, &#39;to&#39;, &#39;not&#39;, &#39;own&#39;, &#39;there&#39;, &#39;this&#39;, &#39;each&#39;, &#39;all&#39;, &#39;more&#39;, &#39;me&#39;, &#39;which&#39;, &#39;himself&#39;, &#39;nor&#39;, &#39;other&#39;, &#39;who&#39;, &#39;same&#39;, &#39;at&#39;, &#39;such&#39;, &#39;t&#39;, &#39;up&#39;, &#39;than&#39;, &#39;can&#39;, &#39;too&#39;, &#39;these&#39;, &#39;while&#39;, &#39;before&#39;, &#39;ourselves&#39;, &#39;he&#39;, &#39;i&#39;, &#39;our&#39;, &#39;its&#39;, &#39;but&#39;, &#39;with&#39;, &#39;because&#39;, &#39;those&#39;, &#39;the&#39;, &#39;it&#39;, &#39;hers&#39;, &#39;just&#39;, &#39;over&#39;, &#39;between&#39;, &#39;had&#39;, &#39;does&#39;, &#39;have&#39;, &#39;and&#39;, &#39;some&#39;, &#39;or&#39;, &#39;only&#39;, &#39;when&#39;, &#39;below&#39;, &#39;in&#39;, &#39;if&#39;, &#39;theirs&#39;, &#39;again&#39;, &#39;his&#39;, &#39;whom&#39;, &#39;above&#39;, &#39;should&#39;, &#39;itself&#39;, &#39;themselves&#39;, &#39;until&#39;, &#39;are&#39;, &#39;she&#39;, &#39;will&#39;, &#39;from&#39;, &#39;into&#39;, &#39;no&#39;, &#39;your&#39;, &#39;few&#39;, &#39;herself&#39;, &#39;of&#39;, &#39;has&#39;, &#39;down&#39;, &#39;were&#39;, &#39;once&#39;, &#39;having&#39;, &#39;them&#39;, &#39;under&#39;, &#39;him&#39;, &#39;do&#39;, &#39;on&#39;, &#39;an&#39;, &#39;yours&#39;, &#39;being&#39;, &#39;off&#39;, &#39;very&#39;, &#39;through&#39;, &#39;most&#39;, &#39;against&#39;, &#39;here&#39;, &#39;is&#39;, &#39;s&#39;, &#39;during&#39;}\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["redditRecToToken = reddit.map(lambda line: (line[0], line[1], tokenize(line[2]),line[3], line[4]))\n\nprint(redditRecToToken.take(5))\n\ndef countTokens(vendorRDD):\n    \"\"\" Count and return the number of tokens\n    Args:\n        vendorRDD (RDD of (recordId, tokenizedValue)): Pair tuple of record ID to tokenized output\n    Returns:\n        count: count of all tokens\n    \"\"\"\n    # TODO: Uncomment the template below and replace <FILL IN> with appropriate code\n    recordCount = vendorRDD.map(lambda line: len(line[0]))\n    recordSum = recordCount.sum()\n    return recordSum\n\ntotalTokens = countTokens(redditRecToToken)\nprint('There are %s tokens in the combined datasets' % totalTokens)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"087a72b7-bda0-4243-ac7b-52e91f2980a6"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">[(&#39;&#34;c0299b0&#34;&#39;, 12, [&#39;anyone&#39;, &#39;else&#39;, &#39;recommended&#39;, &#39;page&#39;, &#39;completely&#39;, &#39;empty&#39;, &#39;mine&#39;], 12, 1), (&#39;&#34;c0299b5&#34;&#39;, 12, [&#39;see&#39;, &#39;beta&#39;, &#39;reddit&#39;, &#39;com&#39;], 12, 1), (&#39;&#34;c0299bv&#34;&#39;, 22, [&#39;new&#39;, &#39;comment&#39;, &#39;system&#39;, &#39;going&#39;, &#39;wonders&#39;, &#39;fibonacci&#39;, &#39;sequence&#39;, &#39;thread&#39;, &#39;http&#39;, &#39;reddit&#39;, &#39;com&#39;, &#39;info&#39;, &#39;2mg72&#39;, &#39;comments&#39;, &#39;c2zuy0&#39;], 22, 1), (&#39;&#34;c0299ey&#34;&#39;, 157, [&#39;aren&#39;, &#39;many&#39;, &#39;changes&#39;], 157, 1), (&#39;&#34;c0299fr&#34;&#39;, 20, [&#39;shouldn&#39;, &#39;tested&#39;, &#39;changes&#39;, &#39;releasing&#39;, &#39;production&#39;, &#39;feels&#39;, &#39;like&#39;, &#39;huge&#39;, &#39;cock&#39;, &#39;release&#39;, &#39;else&#39;, &#39;would&#39;, &#39;explain&#39;, &#39;48&#39;, &#39;hour&#39;, &#39;downtime&#39;, &#39;upgrade&#39;, &#39;edit&#39;, &#39;fixed&#39;, &#39;typo&#39;], 20, 1)]\nThere are 235899 tokens in the combined datasets\n</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">[(&#39;&#34;c0299b0&#34;&#39;, 12, [&#39;anyone&#39;, &#39;else&#39;, &#39;recommended&#39;, &#39;page&#39;, &#39;completely&#39;, &#39;empty&#39;, &#39;mine&#39;], 12, 1), (&#39;&#34;c0299b5&#34;&#39;, 12, [&#39;see&#39;, &#39;beta&#39;, &#39;reddit&#39;, &#39;com&#39;], 12, 1), (&#39;&#34;c0299bv&#34;&#39;, 22, [&#39;new&#39;, &#39;comment&#39;, &#39;system&#39;, &#39;going&#39;, &#39;wonders&#39;, &#39;fibonacci&#39;, &#39;sequence&#39;, &#39;thread&#39;, &#39;http&#39;, &#39;reddit&#39;, &#39;com&#39;, &#39;info&#39;, &#39;2mg72&#39;, &#39;comments&#39;, &#39;c2zuy0&#39;], 22, 1), (&#39;&#34;c0299ey&#34;&#39;, 157, [&#39;aren&#39;, &#39;many&#39;, &#39;changes&#39;], 157, 1), (&#39;&#34;c0299fr&#34;&#39;, 20, [&#39;shouldn&#39;, &#39;tested&#39;, &#39;changes&#39;, &#39;releasing&#39;, &#39;production&#39;, &#39;feels&#39;, &#39;like&#39;, &#39;huge&#39;, &#39;cock&#39;, &#39;release&#39;, &#39;else&#39;, &#39;would&#39;, &#39;explain&#39;, &#39;48&#39;, &#39;hour&#39;, &#39;downtime&#39;, &#39;upgrade&#39;, &#39;edit&#39;, &#39;fixed&#39;, &#39;typo&#39;], 20, 1)]\nThere are 235899 tokens in the combined datasets\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["def timeit(method):\n    '''\n    Decorator to time functions.\n    '''\n    def timed(*args, **kw):\n        ts = time.time()\n        result = method(*args, **kw)\n        te = time.time()\n\n        print('%r took %2.2f sec\\n' % (method.__name__, te-ts))\n              \n        return result\n    return timed"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a846692c-0000-43f4-9c2c-95ef23198900"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["@timeit\ndef term_frequency(df, inputCol, outputCol, hashFeatures=None):\n    '''\n    Returns a DataFrame object containing a new row with the extracted features. \n    Passing hashed=True will return a Featured Hashed matrix.\n    \n    @params:\n        df - DataFrame\n        inputCol - name of input column from DataFrame to find features\n        outputCol - name of the column to save the features\n        hashFeatures - number of features for HashingTF, if None will perform \n            CountVectorization\n    '''\n    \n    # since the number of features was not passed perform standard CountVectorization\n    if hashFeatures is None:\n        cv = CountVectorizer(inputCol=inputCol, outputCol=outputCol)\n        feature_extractor = cv.fit(df)\n    # otherwise perform a feature extractor with \n    else:\n        feature_extractor = HashingTF(\\\n                              inputCol=inputCol, outputCol=outputCol, numFeatures=hashFeatures)\n    \n    # create a new DataFrame using either feature extraction method\n    return feature_extractor.transform(df)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"cb165af5-213c-46fb-8407-b48f7fdf34fd"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["wordsFilteredDF = spark.createDataFrame(redditRecToToken).toDF(\"id\", \"ups\", \"filtered_words\", \"score\", \"viralness\")\n\n# Feature Hash the comment content\n# number of features for Feature Hash matrix, reccomended too use power of 2\nhashDF = term_frequency(\\\n    df=wordsFilteredDF, inputCol=\"filtered_words\", outputCol=\"features\", hashFeatures=1024)\n\n# Display snippet of new DataFrame\nhashDF.select('filtered_words','features').show(5)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"71e8f282-5b9d-4c80-a28d-06a2b9ef0d08"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">&#39;term_frequency&#39; took 0.39 sec\n\n+--------------------+--------------------+\n|      filtered_words|            features|\n+--------------------+--------------------+\n|[anyone, else, re...|(1024,[67,81,106,...|\n|[see, beta, reddi...|(1024,[346,541,55...|\n|[new, comment, sy...|(1024,[92,329,407...|\n|[aren, many, chan...|(1024,[308,637,75...|\n|[shouldn, tested,...|(1024,[49,80,127,...|\n+--------------------+--------------------+\nonly showing top 5 rows\n\n</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">&#39;term_frequency&#39; took 0.39 sec\n\n+--------------------+--------------------+\n      filtered_words|            features|\n+--------------------+--------------------+\n[anyone, else, re...|(1024,[67,81,106,...|\n[see, beta, reddi...|(1024,[346,541,55...|\n[new, comment, sy...|(1024,[92,329,407...|\n[aren, many, chan...|(1024,[308,637,75...|\n[shouldn, tested,...|(1024,[49,80,127,...|\n+--------------------+--------------------+\nonly showing top 5 rows\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["@timeit\ndef random_forest_regression(df, featuresCol, labelCol):\n    '''\n    Returns a DataFrame containing a column of predicted values of the labelCol.\n    Predict the output of labelCol using values in featuresCol y = rf(x).\n    \n    @params:\n        df - DataFrame\n        featuresCol - input features, x\n        labelCol - output variable, y\n    '''\n    # split the training and test data using the holdout method\n    (trainingData, testData) = df.randomSplit([0.8, 0.2])\n    \n    # create the random forest regressor, limit number of trees to ten\n    dtr = RandomForestRegressor(\\\n       featuresCol=featuresCol, labelCol=labelCol)\n    \n    # fit the training data to the regressor to create the model\n    model = dtr.fit(trainingData)\n    \n    # create a DataFrame contained a column with predicted values of the labelCol\n    predictions = model.transform(testData)\n    \n    return predictions"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9e90230a-38d0-4647-90ef-580b7dd15fb2"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["# train random forest regression\nrfPredictions = random_forest_regression(df=hashDF,featuresCol=\"features\",labelCol=\"score\")\n\n# compute the error\nevaluator = RegressionEvaluator(labelCol=\"score\", predictionCol=\"prediction\", metricName=\"rmse\")\nrmse = evaluator.evaluate(rfPredictions)\nprint(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8c1cdd47-3dfe-4e5c-a1f5-4d8b5b7a0ba4"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">&#39;random_forest_regression&#39; took 18.41 sec\n\nRoot Mean Squared Error (RMSE) on test data = 24.8089\n</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">&#39;random_forest_regression&#39; took 18.41 sec\n\nRoot Mean Squared Error (RMSE) on test data = 24.8089\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["rfPredictions.show(10)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6c3d4c34-b052-43cb-ae5e-60e6b995e608"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+---------+---+--------------------+-----+---------+--------------------+------------------+\n|       id|ups|      filtered_words|score|viralness|            features|        prediction|\n+---------+---+--------------------+-----+---------+--------------------+------------------+\n|&#34;c0299b0&#34;| 12|[anyone, else, re...|   12|        1|(1024,[67,81,106,...| 12.58771816992639|\n|&#34;c0299bv&#34;| 22|[new, comment, sy...|   22|        1|(1024,[92,329,407...|12.316584194677791|\n|&#34;c0299ey&#34;|157|[aren, many, chan...|  157|        1|(1024,[308,637,75...| 12.58771816992639|\n|&#34;c0299gj&#34;| 18|[great, see, comm...|   18|        1|(1024,[25,92,179,...|12.780034319084425|\n|&#34;c0299gw&#34;| 16|[doesn, work, ll,...|   16|        1|(1024,[371,374,55...| 12.58771816992639|\n|&#34;c0299h2&#34;|-19|           [deleted]|  -19|        1| (1024,[1018],[1.0])| 4.043190445466253|\n|&#34;c0299h5&#34;|103|[discovered, outs...|  103|        1|(1024,[123,272,42...|12.780034319084425|\n|&#34;c0299iv&#34;| 55|       [anonymously]|   55|        1|   (1024,[73],[1.0])| 12.58771816992639|\n|&#34;c0299jh&#34;| 15|      [hit, refresh]|   15|        1|(1024,[284,790],[...| 12.58771816992639|\n|&#34;c0299kw&#34;|-29|[think, need, hir...|  -29|        1|(1024,[165,217,28...| 12.58771816992639|\n+---------+---+--------------------+-----+---------+--------------------+------------------+\nonly showing top 10 rows\n\n</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+---------+---+--------------------+-----+---------+--------------------+------------------+\n       id|ups|      filtered_words|score|viralness|            features|        prediction|\n+---------+---+--------------------+-----+---------+--------------------+------------------+\n&#34;c0299b0&#34;| 12|[anyone, else, re...|   12|        1|(1024,[67,81,106,...| 12.58771816992639|\n&#34;c0299bv&#34;| 22|[new, comment, sy...|   22|        1|(1024,[92,329,407...|12.316584194677791|\n&#34;c0299ey&#34;|157|[aren, many, chan...|  157|        1|(1024,[308,637,75...| 12.58771816992639|\n&#34;c0299gj&#34;| 18|[great, see, comm...|   18|        1|(1024,[25,92,179,...|12.780034319084425|\n&#34;c0299gw&#34;| 16|[doesn, work, ll,...|   16|        1|(1024,[371,374,55...| 12.58771816992639|\n&#34;c0299h2&#34;|-19|           [deleted]|  -19|        1| (1024,[1018],[1.0])| 4.043190445466253|\n&#34;c0299h5&#34;|103|[discovered, outs...|  103|        1|(1024,[123,272,42...|12.780034319084425|\n&#34;c0299iv&#34;| 55|       [anonymously]|   55|        1|   (1024,[73],[1.0])| 12.58771816992639|\n&#34;c0299jh&#34;| 15|      [hit, refresh]|   15|        1|(1024,[284,790],[...| 12.58771816992639|\n&#34;c0299kw&#34;|-29|[think, need, hir...|  -29|        1|(1024,[165,217,28...| 12.58771816992639|\n+---------+---+--------------------+-----+---------+--------------------+------------------+\nonly showing top 10 rows\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["# train random forest regression\nviralPredictions = random_forest_regression(df=hashDF,featuresCol=\"features\",labelCol=\"viralness\")\n\n# compute the error\nevaluator = RegressionEvaluator(labelCol=\"viralness\", predictionCol=\"prediction\", metricName=\"rmse\")\nrmse = evaluator.evaluate(viralPredictions)\nprint(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"dc6f62b4-66c5-44c7-9b71-2636f23e89d9"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">&#39;random_forest_regression&#39; took 17.60 sec\n\nRoot Mean Squared Error (RMSE) on test data = 0.494195\n</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">&#39;random_forest_regression&#39; took 17.60 sec\n\nRoot Mean Squared Error (RMSE) on test data = 0.494195\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["viralPredictions.show(10)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9686ed4b-e302-404e-a760-1299ac943762"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+---------+---+--------------------+-----+---------+--------------------+------------------+\n|       id|ups|      filtered_words|score|viralness|            features|        prediction|\n+---------+---+--------------------+-----+---------+--------------------+------------------+\n|&#34;c0299fx&#34;| 15|[lots, zero, poin...|   15|        1|(1024,[71,93,330,...|0.5174605093929077|\n|&#34;c0299hy&#34;| 23|[whoa, n, nand, m...|   23|        1|(1024,[282,420,42...|0.5542663769279199|\n|&#34;c0299i8&#34;| 44|[trolled, reddit,...|   44|        1|(1024,[421,556,67...|0.5289265843808844|\n|&#34;c0299il&#34;| 25|[law, mandates, s...|   25|        1|(1024,[192,238,42...|0.5174605093929077|\n|&#34;c0299iv&#34;| 55|       [anonymously]|   55|        1|   (1024,[73],[1.0])|0.5174605093929077|\n|&#34;c0299l5&#34;| 20|[would, like, say...|   20|        1|(1024,[61,214,215...|0.5708458045572689|\n|&#34;c0299lj&#34;| 13|              [rtfa]|   13|        1|  (1024,[125],[1.0])|0.5174605093929077|\n|&#34;c0299mb&#34;| 85|[reddit, didn, no...|   85|        1|(1024,[556,597,92...| 0.565433982157996|\n|&#34;c0299mz&#34;| 35|[tip, delete, red...|   35|        1|(1024,[112,287,55...|0.5289265843808844|\n|&#34;c0299nm&#34;| 13|    [m, complaining]|   13|        1|(1024,[19,282],[1...|0.5174605093929077|\n+---------+---+--------------------+-----+---------+--------------------+------------------+\nonly showing top 10 rows\n\n</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+---------+---+--------------------+-----+---------+--------------------+------------------+\n       id|ups|      filtered_words|score|viralness|            features|        prediction|\n+---------+---+--------------------+-----+---------+--------------------+------------------+\n&#34;c0299fx&#34;| 15|[lots, zero, poin...|   15|        1|(1024,[71,93,330,...|0.5174605093929077|\n&#34;c0299hy&#34;| 23|[whoa, n, nand, m...|   23|        1|(1024,[282,420,42...|0.5542663769279199|\n&#34;c0299i8&#34;| 44|[trolled, reddit,...|   44|        1|(1024,[421,556,67...|0.5289265843808844|\n&#34;c0299il&#34;| 25|[law, mandates, s...|   25|        1|(1024,[192,238,42...|0.5174605093929077|\n&#34;c0299iv&#34;| 55|       [anonymously]|   55|        1|   (1024,[73],[1.0])|0.5174605093929077|\n&#34;c0299l5&#34;| 20|[would, like, say...|   20|        1|(1024,[61,214,215...|0.5708458045572689|\n&#34;c0299lj&#34;| 13|              [rtfa]|   13|        1|  (1024,[125],[1.0])|0.5174605093929077|\n&#34;c0299mb&#34;| 85|[reddit, didn, no...|   85|        1|(1024,[556,597,92...| 0.565433982157996|\n&#34;c0299mz&#34;| 35|[tip, delete, red...|   35|        1|(1024,[112,287,55...|0.5289265843808844|\n&#34;c0299nm&#34;| 13|    [m, complaining]|   13|        1|(1024,[19,282],[1...|0.5174605093929077|\n+---------+---+--------------------+-----+---------+--------------------+------------------+\nonly showing top 10 rows\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["from pyspark.ml.classification import LogisticRegression\nfrom pyspark.mllib.classification import LogisticRegressionWithLBFGS, LogisticRegressionModel, LogisticRegressionWithSGD\nfrom pyspark.mllib.regression import LabeledPoint\n@timeit\ndef logistic_regression(df, featuresCol, labelCol, viralness):\n    '''\n    Returns a DataFrame containing a column of predicted values of the labelCol.\n    Predict the output of labelCol using values in featuresCol y = rf(x).\n    \n    @params:\n        df - DataFrame\n        featuresCol - input features, x\n        labelCol - output variable, y\n    '''\n    # split the training and test data using the holdout method\n    print(df.count())\n    if not viralness:\n      df = df.filter((df.score >=0) & (df.score <10))\n    print(df.show(10))\n    print(df.count())\n    (trainingData, testData) = df.randomSplit([0.8, 0.2])\n    \n    \n    # TODO: Uncomment the lines below and replace <FILL IN> with appropriate code\n    # Given hyperparameters\n    standardization = False\n    elastic_net_param = 0.8\n    reg_param = .3\n    max_iter = 10\n\n    lr = (LogisticRegression(featuresCol=featuresCol, labelCol=labelCol, regParam = reg_param, standardization = standardization, maxIter = max_iter,elasticNetParam = elastic_net_param))\n#     lr = (LogisticRegressionWithLBFGS(featuresCol=featuresCol, labelCol=labelCol, regParam = reg_param, standardization = standardization, maxIter = max_iter,elasticNetParam = elastic_net_param))\n#     model = LogisticRegressionWithLBFGS.train(trainingData, numClasses=5)\n#     print(lr.numClasses)\n#     \n    lr_model_basic = lr.fit(trainingData)\n#     lr_model_basic =LogisticRegressionWithLBFGS.train(trainingData.rdd(),numClasses=5)\n\n    # YOUR CODE HERE\n    # raise NotImplementedError()\n\n    #print('intercept: {0}'.format(lr_model_basic.interceptVector))\n#     print('length of coefficients: {0}'.format(len(lr_model_basic.coefficientMatrix)))\n#     sorted_coefficients = sorted(lr_model_basic.coefficients)[:5]\n    trainingSummary = lr_model_basic.summary\n    accuracy = trainingSummary.accuracy\n    print(accuracy)\n    # create a DataFrame contained a column with predicted values of the labelCol\n    predictions = lr_model_basic.transform(testData)\n    \n    return predictions"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"809b397c-66b7-4f4b-8958-508d83f0da96"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["# train random forest regression\nlrPredictions = logistic_regression(df=hashDF,featuresCol=\"features\",labelCol=\"score\", viralness=False)\n\n# compute the error\nevaluator = RegressionEvaluator(labelCol=\"score\", predictionCol=\"prediction\", metricName=\"rmse\")\nrmse = evaluator.evaluate(lrPredictions)\nprint (\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5c5246be-74e7-43e8-88c7-fcd0d3fa3951"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">26211\n+---------+---+--------------------+-----+---------+--------------------+\n|       id|ups|      filtered_words|score|viralness|            features|\n+---------+---+--------------------+-----+---------+--------------------+\n|&#34;c0299ar&#34;|  3|                [oh]|    3|        0|  (1024,[776],[1.0])|\n|&#34;c0299at&#34;|  3|   [like, one, time]|    3|        0|(1024,[319,386,68...|\n|&#34;c0299aw&#34;|  2|[also, wonder, di...|    2|        0|(1024,[243,704,98...|\n|&#34;c0299bo&#34;|  1|        [woot, nice]|    1|        0|(1024,[435,842],[...|\n|&#34;c0299bz&#34;|  1|     [m, testing, _]|    1|        0|(1024,[11,273,282...|\n|&#34;c0299c4&#34;|  3|             [likes]|    3|        0|  (1024,[372],[1.0])|\n|&#34;c0299ca&#34;|  3|[think, parent, l...|    3|        0|(1024,[492,522,67...|\n|&#34;c0299ch&#34;|  1|[d, rather, dead,...|    1|        0|(1024,[11,243,285...|\n|&#34;c0299co&#34;|  1|[would, happen, l...|    1|        0|(1024,[119,329,33...|\n|&#34;c0299d0&#34;|  1|           [deleted]|    1|        0| (1024,[1018],[1.0])|\n+---------+---+--------------------+-----+---------+--------------------+\nonly showing top 10 rows\n\nNone\n11644\n0.47289318303811056\n&#39;logistic_regression&#39; took 18.34 sec\n\nRoot Mean Squared Error (RMSE) on test data = 2.28253\n</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">26211\n+---------+---+--------------------+-----+---------+--------------------+\n       id|ups|      filtered_words|score|viralness|            features|\n+---------+---+--------------------+-----+---------+--------------------+\n&#34;c0299ar&#34;|  3|                [oh]|    3|        0|  (1024,[776],[1.0])|\n&#34;c0299at&#34;|  3|   [like, one, time]|    3|        0|(1024,[319,386,68...|\n&#34;c0299aw&#34;|  2|[also, wonder, di...|    2|        0|(1024,[243,704,98...|\n&#34;c0299bo&#34;|  1|        [woot, nice]|    1|        0|(1024,[435,842],[...|\n&#34;c0299bz&#34;|  1|     [m, testing, _]|    1|        0|(1024,[11,273,282...|\n&#34;c0299c4&#34;|  3|             [likes]|    3|        0|  (1024,[372],[1.0])|\n&#34;c0299ca&#34;|  3|[think, parent, l...|    3|        0|(1024,[492,522,67...|\n&#34;c0299ch&#34;|  1|[d, rather, dead,...|    1|        0|(1024,[11,243,285...|\n&#34;c0299co&#34;|  1|[would, happen, l...|    1|        0|(1024,[119,329,33...|\n&#34;c0299d0&#34;|  1|           [deleted]|    1|        0| (1024,[1018],[1.0])|\n+---------+---+--------------------+-----+---------+--------------------+\nonly showing top 10 rows\n\nNone\n11644\n0.47289318303811056\n&#39;logistic_regression&#39; took 18.34 sec\n\nRoot Mean Squared Error (RMSE) on test data = 2.28253\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["lrPredictions.show(10)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8d37e417-60f6-409f-b6f9-0d3d78aefb13"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+---------+---+--------------------+-----+---------+--------------------+--------------------+--------------------+----------+\n|       id|ups|      filtered_words|score|viralness|            features|       rawPrediction|         probability|prediction|\n+---------+---+--------------------+-----+---------+--------------------+--------------------+--------------------+----------+\n|&#34;c0299ar&#34;|  3|                [oh]|    3|        0|  (1024,[776],[1.0])|[0.57041738429234...|[0.09878433657725...|       1.0|\n|&#34;c0299bz&#34;|  1|     [m, testing, _]|    1|        0|(1024,[11,273,282...|[0.57041738429234...|[0.09878433657725...|       1.0|\n|&#34;c0299ca&#34;|  3|[think, parent, l...|    3|        0|(1024,[492,522,67...|[0.57041738429234...|[0.09878433657725...|       1.0|\n|&#34;c0299f1&#34;|  1| [strange, comments]|    1|        0|(1024,[241,729],[...|[0.57041738429234...|[0.09878433657725...|       1.0|\n|&#34;c0299fu&#34;|  1|           [deleted]|    1|        0| (1024,[1018],[1.0])|[0.57041738429234...|[0.09878433657725...|       1.0|\n|&#34;c0299g8&#34;|  1|           [deleted]|    1|        0| (1024,[1018],[1.0])|[0.57041738429234...|[0.09878433657725...|       1.0|\n|&#34;c0299nt&#34;|  9|[usability, studi...|    9|        0|(1024,[119,120,20...|[0.57041738429234...|[0.09878433657725...|       1.0|\n|&#34;c0299r5&#34;|  1|           [deleted]|    1|        0| (1024,[1018],[1.0])|[0.57041738429234...|[0.09878433657725...|       1.0|\n|&#34;c0299uz&#34;|  2|[like, remembers,...|    2|        0|(1024,[64,74,225,...|[0.57041738429234...|[0.09878433657725...|       1.0|\n|&#34;c0299v6&#34;|  1|[pictures, gray, ...|    1|        0|(1024,[819,891,97...|[0.57041738429234...|[0.09878433657725...|       1.0|\n+---------+---+--------------------+-----+---------+--------------------+--------------------+--------------------+----------+\nonly showing top 10 rows\n\n</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+---------+---+--------------------+-----+---------+--------------------+--------------------+--------------------+----------+\n       id|ups|      filtered_words|score|viralness|            features|       rawPrediction|         probability|prediction|\n+---------+---+--------------------+-----+---------+--------------------+--------------------+--------------------+----------+\n&#34;c0299ar&#34;|  3|                [oh]|    3|        0|  (1024,[776],[1.0])|[0.57041738429234...|[0.09878433657725...|       1.0|\n&#34;c0299bz&#34;|  1|     [m, testing, _]|    1|        0|(1024,[11,273,282...|[0.57041738429234...|[0.09878433657725...|       1.0|\n&#34;c0299ca&#34;|  3|[think, parent, l...|    3|        0|(1024,[492,522,67...|[0.57041738429234...|[0.09878433657725...|       1.0|\n&#34;c0299f1&#34;|  1| [strange, comments]|    1|        0|(1024,[241,729],[...|[0.57041738429234...|[0.09878433657725...|       1.0|\n&#34;c0299fu&#34;|  1|           [deleted]|    1|        0| (1024,[1018],[1.0])|[0.57041738429234...|[0.09878433657725...|       1.0|\n&#34;c0299g8&#34;|  1|           [deleted]|    1|        0| (1024,[1018],[1.0])|[0.57041738429234...|[0.09878433657725...|       1.0|\n&#34;c0299nt&#34;|  9|[usability, studi...|    9|        0|(1024,[119,120,20...|[0.57041738429234...|[0.09878433657725...|       1.0|\n&#34;c0299r5&#34;|  1|           [deleted]|    1|        0| (1024,[1018],[1.0])|[0.57041738429234...|[0.09878433657725...|       1.0|\n&#34;c0299uz&#34;|  2|[like, remembers,...|    2|        0|(1024,[64,74,225,...|[0.57041738429234...|[0.09878433657725...|       1.0|\n&#34;c0299v6&#34;|  1|[pictures, gray, ...|    1|        0|(1024,[819,891,97...|[0.57041738429234...|[0.09878433657725...|       1.0|\n+---------+---+--------------------+-----+---------+--------------------+--------------------+--------------------+----------+\nonly showing top 10 rows\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["# train random forest regression\nlrViralPredictions = logistic_regression(df=hashDF,featuresCol=\"features\",labelCol=\"viralness\", viralness=True)\n\n# compute the error\nevaluator = RegressionEvaluator(labelCol=\"viralness\", predictionCol=\"prediction\", metricName=\"rmse\")\nrmse = evaluator.evaluate(lrViralPredictions)\nprint (\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a881e59c-6ffb-43ab-8cd9-cbedb3e58e72"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">26211\n+---------+---+--------------------+-----+---------+--------------------+\n|       id|ups|      filtered_words|score|viralness|            features|\n+---------+---+--------------------+-----+---------+--------------------+\n|&#34;c0299b0&#34;| 12|[anyone, else, re...|   12|        1|(1024,[67,81,106,...|\n|&#34;c0299b5&#34;| 12|[see, beta, reddi...|   12|        1|(1024,[346,541,55...|\n|&#34;c0299bv&#34;| 22|[new, comment, sy...|   22|        1|(1024,[92,329,407...|\n|&#34;c0299ey&#34;|157|[aren, many, chan...|  157|        1|(1024,[308,637,75...|\n|&#34;c0299fr&#34;| 20|[shouldn, tested,...|   20|        1|(1024,[49,80,127,...|\n|&#34;c0299fx&#34;| 15|[lots, zero, poin...|   15|        1|(1024,[71,93,330,...|\n|&#34;c0299gj&#34;| 18|[great, see, comm...|   18|        1|(1024,[25,92,179,...|\n|&#34;c0299go&#34;| 77|[kept, hitting, r...|   77|        1|(1024,[71,183,912...|\n|&#34;c0299gs&#34;| 73|[subreddits, gett...|   73|        1|(1024,[176,178,23...|\n|&#34;c0299gw&#34;| 16|[doesn, work, ll,...|   16|        1|(1024,[371,374,55...|\n+---------+---+--------------------+-----+---------+--------------------+\nonly showing top 10 rows\n\nNone\n26211\n0.5019600344201166\n&#39;logistic_regression&#39; took 6.98 sec\n\nRoot Mean Squared Error (RMSE) on test data = 0.702214\n</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">26211\n+---------+---+--------------------+-----+---------+--------------------+\n       id|ups|      filtered_words|score|viralness|            features|\n+---------+---+--------------------+-----+---------+--------------------+\n&#34;c0299b0&#34;| 12|[anyone, else, re...|   12|        1|(1024,[67,81,106,...|\n&#34;c0299b5&#34;| 12|[see, beta, reddi...|   12|        1|(1024,[346,541,55...|\n&#34;c0299bv&#34;| 22|[new, comment, sy...|   22|        1|(1024,[92,329,407...|\n&#34;c0299ey&#34;|157|[aren, many, chan...|  157|        1|(1024,[308,637,75...|\n&#34;c0299fr&#34;| 20|[shouldn, tested,...|   20|        1|(1024,[49,80,127,...|\n&#34;c0299fx&#34;| 15|[lots, zero, poin...|   15|        1|(1024,[71,93,330,...|\n&#34;c0299gj&#34;| 18|[great, see, comm...|   18|        1|(1024,[25,92,179,...|\n&#34;c0299go&#34;| 77|[kept, hitting, r...|   77|        1|(1024,[71,183,912...|\n&#34;c0299gs&#34;| 73|[subreddits, gett...|   73|        1|(1024,[176,178,23...|\n&#34;c0299gw&#34;| 16|[doesn, work, ll,...|   16|        1|(1024,[371,374,55...|\n+---------+---+--------------------+-----+---------+--------------------+\nonly showing top 10 rows\n\nNone\n26211\n0.5019600344201166\n&#39;logistic_regression&#39; took 6.98 sec\n\nRoot Mean Squared Error (RMSE) on test data = 0.702214\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["lrViralPredictions.show(10)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"fd0b5b12-141c-43bd-a73e-5749ad93bccb"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+---------+---+--------------------+-----+---------+--------------------+--------------------+--------------------+----------+\n|       id|ups|      filtered_words|score|viralness|            features|       rawPrediction|         probability|prediction|\n+---------+---+--------------------+-----+---------+--------------------+--------------------+--------------------+----------+\n|&#34;c0299gw&#34;| 16|[doesn, work, ll,...|   16|        1|(1024,[371,374,55...|[-0.0078401778404...|[0.49803996557988...|       1.0|\n|&#34;c0299hd&#34;| 27|    [lurked, reddit]|   27|        1|(1024,[556,621],[...|[-0.0078401778404...|[0.49803996557988...|       1.0|\n|&#34;c0299i8&#34;| 44|[trolled, reddit,...|   44|        1|(1024,[421,556,67...|[-0.0078401778404...|[0.49803996557988...|       1.0|\n|&#34;c0299ib&#34;| 37|              [mind]|   37|        1|  (1024,[704],[1.0])|[-0.0078401778404...|[0.49803996557988...|       1.0|\n|&#34;c0299im&#34;| 11|[even, trouble, g...|   11|        1|(1024,[93,100,122...|[-0.0078401778404...|[0.49803996557988...|       1.0|\n|&#34;c0299iv&#34;| 55|       [anonymously]|   55|        1|   (1024,[73],[1.0])|[-0.0078401778404...|[0.49803996557988...|       1.0|\n|&#34;c0299kw&#34;|-29|[think, need, hir...|  -29|        1|(1024,[165,217,28...|[-0.0078401778404...|[0.49803996557988...|       1.0|\n|&#34;c0299l5&#34;| 20|[would, like, say...|   20|        1|(1024,[61,214,215...|[-0.0078401778404...|[0.49803996557988...|       1.0|\n|&#34;c0299lj&#34;| 13|              [rtfa]|   13|        1|  (1024,[125],[1.0])|[-0.0078401778404...|[0.49803996557988...|       1.0|\n|&#34;c0299lk&#34;| 67|[reading, first, ...|   67|        1|(1024,[231,398,41...|[-0.0078401778404...|[0.49803996557988...|       1.0|\n+---------+---+--------------------+-----+---------+--------------------+--------------------+--------------------+----------+\nonly showing top 10 rows\n\n</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+---------+---+--------------------+-----+---------+--------------------+--------------------+--------------------+----------+\n       id|ups|      filtered_words|score|viralness|            features|       rawPrediction|         probability|prediction|\n+---------+---+--------------------+-----+---------+--------------------+--------------------+--------------------+----------+\n&#34;c0299gw&#34;| 16|[doesn, work, ll,...|   16|        1|(1024,[371,374,55...|[-0.0078401778404...|[0.49803996557988...|       1.0|\n&#34;c0299hd&#34;| 27|    [lurked, reddit]|   27|        1|(1024,[556,621],[...|[-0.0078401778404...|[0.49803996557988...|       1.0|\n&#34;c0299i8&#34;| 44|[trolled, reddit,...|   44|        1|(1024,[421,556,67...|[-0.0078401778404...|[0.49803996557988...|       1.0|\n&#34;c0299ib&#34;| 37|              [mind]|   37|        1|  (1024,[704],[1.0])|[-0.0078401778404...|[0.49803996557988...|       1.0|\n&#34;c0299im&#34;| 11|[even, trouble, g...|   11|        1|(1024,[93,100,122...|[-0.0078401778404...|[0.49803996557988...|       1.0|\n&#34;c0299iv&#34;| 55|       [anonymously]|   55|        1|   (1024,[73],[1.0])|[-0.0078401778404...|[0.49803996557988...|       1.0|\n&#34;c0299kw&#34;|-29|[think, need, hir...|  -29|        1|(1024,[165,217,28...|[-0.0078401778404...|[0.49803996557988...|       1.0|\n&#34;c0299l5&#34;| 20|[would, like, say...|   20|        1|(1024,[61,214,215...|[-0.0078401778404...|[0.49803996557988...|       1.0|\n&#34;c0299lj&#34;| 13|              [rtfa]|   13|        1|  (1024,[125],[1.0])|[-0.0078401778404...|[0.49803996557988...|       1.0|\n&#34;c0299lk&#34;| 67|[reading, first, ...|   67|        1|(1024,[231,398,41...|[-0.0078401778404...|[0.49803996557988...|       1.0|\n+---------+---+--------------------+-----+---------+--------------------+--------------------+--------------------+----------+\nonly showing top 10 rows\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"81e954b6-7a70-4241-a439-1a3652aff9a3"}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"RDC_DataClean_LR_RF_Balanced","dashboards":[],"language":"python","widgets":{},"notebookOrigID":1537880315604143}},"nbformat":4,"nbformat_minor":0}
