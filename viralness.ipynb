{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e64a3b541e7c4603b2680dbdfd917be1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>0</td><td>application_1607295858388_0001</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-172-31-90-196.ec2.internal:20888/proxy/application_1607295858388_0001/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-172-31-91-212.ec2.internal:8042/node/containerlogs/container_1607295858388_0001_01_000001/livy\">Link</a></td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from pyspark.ml.linalg import SparseVector\n",
    "from pyspark.sql.functions import explode\n",
    "from pyspark import SparkFiles\n",
    "from pyspark.sql import Row\n",
    "\n",
    "import bz2\n",
    "import json\n",
    "import time\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import * # CountVectorizer, Tokenizer, RegexTokenizer, HashingTF\n",
    "from pyspark.ml.regression import * # RandomForestRegressor, LinearRegression, DecisionTreeRegressor\n",
    "from pyspark.ml.evaluation import RegressionEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3c5496f881e4a67818ada9f1cd529e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def timeit(method):\n",
    "    '''\n",
    "    Decorator to time functions.\n",
    "    '''\n",
    "    def timed(*args, **kw):\n",
    "        ts = time.time()\n",
    "        result = method(*args, **kw)\n",
    "        te = time.time()\n",
    "\n",
    "        print('%r took %2.2f sec\\n' % (method.__name__, te-ts))\n",
    "              \n",
    "        return result\n",
    "    return timed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eda3e7cbc7b1427e97bcd7e6a4cee032",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import re\n",
    "# DATAFILE_PATTERN = '^(.+),\"(.+)\",(.*),(.*),(.*)'\n",
    "ID_PATTERN = '\"id\":(.*?(?=,|}))'\n",
    "UPS_PATTERN = '\"ups\":(.*?(?=,|}))'\n",
    "BODY_PATTERN = '\"body\":(.*?(?=,|}))'\n",
    "# DOWNS_PATTERN = '\"downs\":(.*?(?=,|}))'\n",
    "SCORE_PATTERN = '\"score\":(.*?(?=,|}))'\n",
    "# CONTROVERSIALITY_PATTERN = '\"controversiality\":(.*?(?=,|}))'\n",
    "\n",
    "def removeQuotes(s):\n",
    "    \"\"\" Remove quotation marks from an input string\n",
    "    Args:\n",
    "        s (str): input string that might have the quote \"\" characters\n",
    "    Returns:\n",
    "        str: a string without the quote characters\n",
    "    \"\"\"\n",
    "    return ''.join(i for i in s if i!='\"')\n",
    "\n",
    "def parseDatafileLine(datafileLine):\n",
    "    \"\"\" Parse a line of the data file using the specified regular expression pattern\n",
    "    Args:\n",
    "        datafileLine (str): input string that is a line from the data file\n",
    "    Returns:\n",
    "        tuple: a tuple including the parsed results using the given regular expression and without the quote characters\n",
    "    \"\"\"\n",
    "    id_match = re.search(ID_PATTERN, datafileLine.decode('utf-8'))\n",
    "    ups_match = re.search(UPS_PATTERN, datafileLine.decode('utf-8'))\n",
    "    body_match = re.search(BODY_PATTERN, datafileLine.decode('utf-8'))\n",
    "    score_match = re.search(SCORE_PATTERN, datafileLine.decode('utf-8'))\n",
    "    \n",
    "    if (id_match is None) or (ups_match is None) or (body_match is None) or (score_match is None):\n",
    "        print('Invalid datafile line: %s' % datafileLine)\n",
    "        return (datafileLine, -1)\n",
    "    else:\n",
    "        viralness = 0\n",
    "        if int(score_match.group(1)) < -10 or int(score_match.group(1)) > 10:\n",
    "            viralness = 1\n",
    "        comment = (id_match.group(1), int(ups_match.group(1)), removeQuotes(body_match.group(1)), int(score_match.group(1)), viralness)\n",
    "        return (comment, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a08f717236364069bdfddd0da9765335",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://dsml-vasu-simar-daniel/RC_2015-0* - Read 156758730 lines, successfully parsed 147697364 lines, failed to parse 0 lines, 9061366 lines were deleted\n",
      "'loadData' took 211.51 sec"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "from pyspark import SparkFiles\n",
    "\n",
    "#RC_PATH = '/FileStore/shared_uploads/ddk1@andrew.cmu.edu/RC_2007_10'\n",
    "RC_PATH = 's3://dsml-vasu-simar-daniel/RC_2015-0*'\n",
    "\n",
    "def parseData(path):\n",
    "    \"\"\" Parse a data file\n",
    "    Args:\n",
    "        filename (str): input file name of the data file\n",
    "    Returns:\n",
    "        RDD: a RDD of parsed lines\n",
    "    \"\"\"\n",
    "#     sc.addFile(path)\n",
    "    return (sc\n",
    "            .textFile(path, 4, 0)\n",
    "            .map(parseDatafileLine)\n",
    "            .cache())\n",
    "@timeit\n",
    "def loadData(path):\n",
    "    \"\"\" Load a data file\n",
    "    Args:\n",
    "        path (str): input file name of the data file\n",
    "    Returns:\n",
    "        RDD: a RDD of parsed valid lines\n",
    "    \"\"\"\n",
    "\n",
    "    raw = parseData(path).cache()\n",
    "    \n",
    "    failed = (raw\n",
    "              .filter(lambda s: s[1] == -1)\n",
    "              .map(lambda s: s[0]))\n",
    "    for line in failed.take(10):\n",
    "        print('%s - Invalid datafile line: %s' % (path, line))\n",
    "    \n",
    "    deleted = (raw\n",
    "             .filter(lambda s: s[0][2] == '[deleted]')\n",
    "             .map(lambda s: s[0]))\n",
    "    \n",
    "    valid = (raw\n",
    "             .filter(lambda s: s[1] == 1)\n",
    "             .filter(lambda s: s[0][2] != '[deleted]')\n",
    "             .map(lambda s: s[0])\n",
    "             .cache())\n",
    "    print('%s - Read %d lines, successfully parsed %d lines, failed to parse %d lines, %d lines were deleted' % (path,\n",
    "                                                                                                                 raw.count(),\n",
    "                                                                                                                 valid.count(),\n",
    "                                                                                                                 failed.count(),\n",
    "                                                                                                                 deleted.count()))\n",
    "    return valid\n",
    "\n",
    "reddit = loadData(RC_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5478dbc456b8462cb0462502692c3b50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+--------------------+-----+---------+\n",
      "|       id|ups|                body|score|viralness|\n",
      "+---------+---+--------------------+-----+---------+\n",
      "|\"cnas8zv\"| 14|Most of us have s...|   14|        1|\n",
      "|\"cnas8zw\"|  3|But Mill's career...|    3|        0|\n",
      "|\"cnas8zx\"|  1|Mine uses a strai...|    1|        0|\n",
      "|\"cnas8zz\"|  2|           Very fast|    2|        0|\n",
      "|\"cnas900\"|  6|The guy is a prof...|    6|        0|\n",
      "+---------+---+--------------------+-----+---------+\n",
      "only showing top 5 rows"
     ]
    }
   ],
   "source": [
    "sentenceDF = reddit.toDF().selectExpr(\"_1 as id\", \"_2 as ups\", \"_3 as body\", \"_4 as score\", \"_5 as viralness\")\n",
    "sentenceDF.show(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea7a3d2291314e849ab420adeeceb4af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "split_regex = r'\\W+'\n",
    "linebreak_regex = r'\\\\r\\\\n\\\\r\\\\n'\n",
    "\n",
    "def simpleTokenize(string):\n",
    "    \"\"\" A simple implementation of input string tokenization\n",
    "    Args:\n",
    "        string (str): input string\n",
    "    Returns:\n",
    "        list: a list of tokens\n",
    "    \"\"\"\n",
    "    linebreak_removed_string = re.sub(linebreak_regex, \" \", string)\n",
    "    return list(filter(None, re.split(split_regex, linebreak_removed_string.lower())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bcee975369c4ef1b8ec76f096132a9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These are the stopwords: {'out', 'we', 'was', 'how', 'myself', 'for', 'they', 'about', 'then', 'both', 'so', 'don', 'as', 'any', 'after', 'you', 'why', 'been', 'where', 'by', 'yourself', 'a', 'did', 'their', 'doing', 'be', 'further', 'ours', 'now', 'am', 'her', 'yourselves', 'that', 'what', 'my', 'to', 'not', 'own', 'there', 'this', 'each', 'all', 'more', 'me', 'which', 'himself', 'nor', 'other', 'who', 'same', 'at', 'such', 't', 'up', 'than', 'can', 'too', 'these', 'while', 'before', 'ourselves', 'he', 'i', 'our', 'its', 'but', 'with', 'because', 'those', 'the', 'it', 'hers', 'just', 'over', 'between', 'had', 'does', 'have', 'and', 'some', 'or', 'only', 'when', 'below', 'in', 'if', 'theirs', 'again', 'his', 'whom', 'above', 'should', 'itself', 'themselves', 'until', 'are', 'she', 'will', 'from', 'into', 'no', 'your', 'few', 'herself', 'of', 'has', 'down', 'were', 'once', 'having', 'them', 'under', 'him', 'do', 'on', 'an', 'yours', 'being', 'off', 'very', 'through', 'most', 'against', 'here', 'is', 's', 'during'}"
     ]
    }
   ],
   "source": [
    "# stopfile = \"https://raw.githubusercontent.com/10605/data/master/hw1/stopwords.txt\"\n",
    "# sc.addFile(stopfile)\n",
    "# stopwords = set(sc.textFile(\"file://\" + SparkFiles.get(\"stopwords.txt\")).collect())\n",
    "stopwords = set(sc.textFile(\"s3://dsml-vasu-simar-daniel/stopwords.txt\").collect())\n",
    "print('These are the stopwords: %s' % stopwords)\n",
    "\n",
    "def tokenize(string):\n",
    "    \"\"\" An implementation of input string tokenization that excludes stopwords\n",
    "    Args:\n",
    "        string (str): input string\n",
    "    Returns:\n",
    "        list: a list of tokens without stopwords\n",
    "    \"\"\"\n",
    "    return list(filter(lambda word: word not in stopwords,simpleTokenize(string)))\n",
    "\n",
    "\n",
    "\n",
    "# pattern = \"\\\\W\"\n",
    "# # tokenizer = RegexTokenizer(inputCol=\"body\", outputCol=\"words\", pattern=pattern)\n",
    "# tokenizer = Tokenizer(inputCol=\"body\", outputCol=\"words\")\n",
    "# wordsDF = tokenizer.transform(sentenceDF)\n",
    "\n",
    "# # Remove stop words\n",
    "# remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered_words\")\n",
    "# wordsFilteredDF = remover.transform(wordsDF)\n",
    "\n",
    "# # Remove body and words since they will no longer be used\n",
    "# wordsFilteredDF = wordsFilteredDF.select('id','ups','filtered_words','score','viralness')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44e5c7fb80294186a5e97895b19005b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('\"cnas8zv\"', 14, ['us', 'family', 'members', 'like', 'family', 'like'], 14, 1), ('\"cnas8zw\"', 3, ['mill', 'career', 'way', 'better', 'bentham', 'like'], 3, 0), ('\"cnas8zx\"', 1, ['mine', 'uses', 'strait', 'razor'], 1, 0), ('\"cnas8zz\"', 2, ['fast'], 2, 0), ('\"cnas900\"', 6, ['guy', 'professional'], 6, 0)]\n",
      "There are 1329276276 tokens in the combined datasets"
     ]
    }
   ],
   "source": [
    "redditRecToToken = reddit.map(lambda line: (line[0], line[1], tokenize(line[2]),line[3], line[4]))\n",
    "\n",
    "print(redditRecToToken.take(5))\n",
    "\n",
    "def countTokens(vendorRDD):\n",
    "    \"\"\" Count and return the number of tokens\n",
    "    Args:\n",
    "        vendorRDD (RDD of (recordId, tokenizedValue)): Pair tuple of record ID to tokenized output\n",
    "    Returns:\n",
    "        count: count of all tokens\n",
    "    \"\"\"\n",
    "    # TODO: Uncomment the template below and replace <FILL IN> with appropriate code\n",
    "    recordCount = vendorRDD.map(lambda line: len(line[0]))\n",
    "    recordSum = recordCount.sum()\n",
    "    return recordSum\n",
    "\n",
    "totalTokens = countTokens(redditRecToToken)\n",
    "print('There are %s tokens in the combined datasets' % totalTokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7652500806274347abd83ca5bd189f6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@timeit\n",
    "def term_frequency(df, inputCol, outputCol, hashFeatures=None):\n",
    "    '''\n",
    "    Returns a DataFrame object containing a new row with the extracted features. \n",
    "    Passing hashed=True will return a Featured Hashed matrix.\n",
    "    \n",
    "    @params:\n",
    "        df - DataFrame\n",
    "        inputCol - name of input column from DataFrame to find features\n",
    "        outputCol - name of the column to save the features\n",
    "        hashFeatures - number of features for HashingTF, if None will perform \n",
    "            CountVectorization\n",
    "    '''\n",
    "    \n",
    "    # since the number of features was not passed perform standard CountVectorization\n",
    "    if hashFeatures is None:\n",
    "        cv = CountVectorizer(inputCol=inputCol, outputCol=outputCol)\n",
    "        feature_extractor = cv.fit(df)\n",
    "    # otherwise perform a feature extractor with \n",
    "    else:\n",
    "        feature_extractor = HashingTF(\\\n",
    "                              inputCol=inputCol, outputCol=outputCol, numFeatures=hashFeatures)\n",
    "    \n",
    "    # create a new DataFrame using either feature extraction method\n",
    "    return feature_extractor.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "328e477f1dc84c3ab849d8098a092c2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'term_frequency' took 0.36 sec\n",
      "\n",
      "+--------------------+--------------------+\n",
      "|      filtered_words|            features|\n",
      "+--------------------+--------------------+\n",
      "|[us, family, memb...|(1024,[368,386,45...|\n",
      "|[mill, career, wa...|(1024,[102,205,31...|\n",
      "|[mine, uses, stra...|(1024,[120,423,55...|\n",
      "|              [fast]|  (1024,[863],[1.0])|\n",
      "| [guy, professional]|(1024,[931,955],[...|\n",
      "+--------------------+--------------------+\n",
      "only showing top 5 rows"
     ]
    }
   ],
   "source": [
    "wordsFilteredDF = spark.createDataFrame(redditRecToToken).toDF(\"id\", \"ups\", \"filtered_words\", \"score\", \"viralness\")\n",
    "\n",
    "# Feature Hash the comment content\n",
    "# number of features for Feature Hash matrix, reccomended too use power of 2\n",
    "hashDF = term_frequency(\\\n",
    "    df=wordsFilteredDF, inputCol=\"filtered_words\", outputCol=\"features\", hashFeatures=1024)\n",
    "\n",
    "# Display snippet of new DataFrame\n",
    "hashDF.select('filtered_words','features').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "890906c6649a489cbd8ea1b55ae255b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@timeit\n",
    "def random_forest_regression(df, featuresCol, labelCol):\n",
    "    '''\n",
    "    Returns a DataFrame containing a column of predicted values of the labelCol.\n",
    "    Predict the output of labelCol using values in featuresCol y = rf(x).\n",
    "    \n",
    "    @params:\n",
    "        df - DataFrame\n",
    "        featuresCol - input features, x\n",
    "        labelCol - output variable, y\n",
    "    '''\n",
    "    # split the training and test data using the holdout method\n",
    "    (trainingData, testData) = df.randomSplit([0.8, 0.2])\n",
    "    \n",
    "    # create the random forest regressor, limit number of trees to ten\n",
    "    dtr = RandomForestRegressor(\\\n",
    "       featuresCol=featuresCol, labelCol=labelCol)\n",
    "    \n",
    "    # fit the training data to the regressor to create the model\n",
    "    model = dtr.fit(trainingData)\n",
    "    \n",
    "    # create a DataFrame contained a column with predicted values of the labelCol\n",
    "    predictions = model.transform(testData)\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8a121c0b74c43e0b7ca812abd62909a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'random_forest_regression' took 1777.49 sec\n",
      "\n",
      "Root Mean Squared Error (RMSE) on test data = 0.266187"
     ]
    }
   ],
   "source": [
    "# train random forest regression\n",
    "rfpredictions = random_forest_regression(df=hashDF,featuresCol=\"features\",labelCol=\"viralness\")\n",
    "\n",
    "# compute the error\n",
    "evaluator = RegressionEvaluator(labelCol=\"viralness\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = evaluator.evaluate(rfpredictions)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddb10f97e3984322ae15027065127cad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+--------------------+-----+---------+--------------------+-------------------+\n",
      "|       id|ups|      filtered_words|score|viralness|            features|         prediction|\n",
      "+---------+---+--------------------+-----+---------+--------------------+-------------------+\n",
      "|\"cnas90j\"|  2|[religion, doesn,...|    2|        0|(1024,[50,60,255,...|0.07515022047761011|\n",
      "|\"cnas90k\"|  2|        [hey, rocky]|    2|        0|(1024,[594,724],[...|0.07515022047761011|\n",
      "|\"cnas90o\"|  1| [agreed, get, sale]|    1|        0|(1024,[511,567,88...|0.07515022047761011|\n",
      "|\"cnas90t\"|  1|[chappelle, https...|    1|        0|(1024,[257,322,38...|0.07806345262040863|\n",
      "|\"cnas90y\"|  2|[thought, wanted,...|    2|        0|(1024,[303,386,69...| 0.0756647834679763|\n",
      "|\"cnas912\"|  3|[ll, try, find, g...|    3|        0|(1024,[95,159,174...|0.07056895981187288|\n",
      "|\"cnas914\"|  1|        [like, idea]|    1|        0|(1024,[386,726],[...| 0.0756647834679763|\n",
      "|\"cnas918\"|  3|[haha, guilty, ve...|    3|        0|(1024,[0,150,266,...|0.09010088236580271|\n",
      "|\"cnas91e\"|  2|[words, like, awe...|    2|        0|(1024,[386,575,93...| 0.0756647834679763|\n",
      "|\"cnas91g\"|  2|[health, insuranc...|    2|        0|(1024,[25,63,325,...| 0.0756647834679763|\n",
      "|\"cnas91l\"|  1|       [re, talking]|    1|        0|(1024,[984,985],[...|0.07515022047761011|\n",
      "|\"cnas91o\"|  4|[would, say, coin...|    4|        0|(1024,[259,660,70...|0.07515022047761011|\n",
      "|\"cnas91q\"|  1|            [thanks]|    1|        0|  (1024,[606],[1.0])|0.05898114352142815|\n",
      "|\"cnas929\"|  1|[accepting, schil...|    1|        0|(1024,[245,300,81...|0.07515022047761011|\n",
      "|\"cnas92c\"|  2|[mind, sharing, s...|    2|        0|(1024,[299,309,36...|0.07515022047761011|\n",
      "|\"cnas92m\"|  2|[amp, 009, n, n, ...|    2|        0|(1024,[14,35,101,...|0.06609244933643588|\n",
      "|\"cnas92s\"|  1|[ve, lot, faceboo...|    1|        0|(1024,[120,185,18...|0.07515022047761011|\n",
      "|\"cnas92w\"|  4|               [sam]|    4|        0|  (1024,[864],[1.0])|0.07515022047761011|\n",
      "|\"cnas93b\"|  1|[noticed, someone...|    1|        0|(1024,[5,53,72,20...|0.05898114352142815|\n",
      "|\"cnas93c\"|  1| [give, oc, name, p]|    1|        0|(1024,[276,303,86...|0.07515022047761011|\n",
      "|\"cnas93f\"|  1|          [yeah, np]|    1|        0|(1024,[145,244],[...|0.07515022047761011|\n",
      "|\"cnas93m\"| 23|[players, shit, c...|   23|        1|(1024,[247,296,34...|0.07970081026058502|\n",
      "|\"cnas93w\"|  1|[hey, u, doc_brietz]|    1|        0|(1024,[412,594,98...|0.07515022047761011|\n",
      "|\"cnas93x\"|  2|[picture, lost, b...|    2|        0|(1024,[405,638,72...|0.07515022047761011|\n",
      "|\"cnas93y\"|  3|        [villainous]|    3|        0|  (1024,[413],[1.0])|0.07515022047761011|\n",
      "|\"cnas944\"| 14|[mean, hackett, d...|   14|        1|(1024,[351,637,65...|0.07515022047761011|\n",
      "|\"cnas94l\"|  4|      [friend, told]|    4|        0|(1024,[150,690],[...|0.07515022047761011|\n",
      "|\"cnas94m\"|  1|         [m, 1, yes]|    1|        0|(1024,[478,712,83...|0.07515022047761011|\n",
      "|\"cnas94n\"|  0|[get, feeling, t2...|    0|        0|(1024,[149,194,44...|0.07515022047761011|\n",
      "|\"cnas94t\"|  1|   [atlanta, braves]|    1|        0|(1024,[291,319],[...|0.07515022047761011|\n",
      "|\"cnas94u\"|  1|[wife, says, fran...|    1|        0|(1024,[34,135,813...|0.07515022047761011|\n",
      "|\"cnas954\"|  1|[r, space, would,...|    1|        0|(1024,[112,226,25...|0.07515022047761011|\n",
      "|\"cnas959\"|  1|[steam, support, ...|    1|        0|(1024,[64,602,679...|0.08488974802877589|\n",
      "|\"cnas95n\"| 25|[monocorp, sells, x]|   25|        1|(1024,[46,668,802...|0.07515022047761011|\n",
      "|\"cnas95r\"|  3|[ve, stuck, coval...|    3|        0|(1024,[63,113,161...|0.07407907660434324|\n",
      "|\"cnas95t\"|  1|[hadn, realized, ...|    1|        0|(1024,[140,234,30...| 0.0756647834679763|\n",
      "|\"cnas961\"| -2|[http, 40, media,...|   -2|        0|(1024,[171,261,29...|0.09881047127605651|\n",
      "|\"cnas974\"|  2|[horr, u00cdvel, ...|    2|        0|(1024,[391,489,60...| 0.0812708042677885|\n",
      "|\"cnas97a\"|  1|[could, imagine, ...|    1|        0|(1024,[4,47,309],...|0.07515022047761011|\n",
      "|\"cnas97c\"|  1|[unless, original...|    1|        0|(1024,[185,588,65...|0.07970081026058502|\n",
      "|\"cnas97d\"|  1|[happy, new, year...|    1|        0|(1024,[89,155,249...|0.09850880237775608|\n",
      "|\"cnas97f\"|  1|[gt, wanted, wild...|    1|        0|(1024,[101,213,52...|0.08015566514991804|\n",
      "|\"cnas97j\"|  0|[photo, taken, me...|    0|        0|(1024,[271,401,54...|0.07515022047761011|\n",
      "|\"cnas97k\"|  1|[awesome, person,...|    1|        0|(1024,[208,251,50...|0.05898114352142815|\n",
      "|\"cnas97s\"|  3|[think, d, still,...|    3|        0|(1024,[360,396,44...|0.07515022047761011|\n",
      "|\"cnas97x\"|  2|[look, beautiful,...|    2|        0|(1024,[68,197,225...|0.07515022047761011|\n",
      "|\"cnas98e\"|  1|[got, goosebumps,...|    1|        0|(1024,[726,743,79...|0.07515022047761011|\n",
      "|\"cnas98i\"|  1|  [many, baht, bath]|    1|        0|(1024,[207,308,69...|0.07515022047761011|\n",
      "|\"cnas98k\"|  3|              [yeah]|    3|        0|  (1024,[145],[1.0])|0.07515022047761011|\n",
      "|\"cnas98n\"|  1|         [feel, bad]|    1|        0|(1024,[382,459],[...|0.07515022047761011|\n",
      "|\"cnas98t\"|  1|[268, nbest, rega...|    1|        0|(1024,[169,315,69...|0.07515022047761011|\n",
      "|\"cnas98v\"| 10|[getting, water, ...|   10|        0|(1024,[26,75,111,...| 0.0756647834679763|\n",
      "|\"cnas98y\"| 13|          [fairness]|   13|        1|  (1024,[260],[1.0])|0.07515022047761011|\n",
      "|\"cnas990\"|  2|[exactly, d, prob...|    2|        0|(1024,[51,227,441...|0.07515022047761011|\n",
      "|\"cnas993\"| 20|      [wasteland, 2]|   20|        1|(1024,[85,675],[1...|0.07515022047761011|\n",
      "|\"cnas994\"|  1|[well, makes, two...|    1|        0|(1024,[304,368,55...|0.07515022047761011|\n",
      "|\"cnas99e\"|-28|[bro, skip, weddi...|  -28|        1|(1024,[125,198,25...|0.07515022047761011|\n",
      "|\"cnas99j\"|  1|[forget, inhumans...|    1|        0|(1024,[79,210,561...|0.07970081026058502|\n",
      "|\"cnas99l\"|  1| [thank, real, warm]|    1|        0|(1024,[180,362,39...|0.06189252782531847|\n",
      "|\"cnas99t\"|  1|[sent, n, nhappy,...|    1|        0|(1024,[261,391,43...| 0.0812708042677885|\n",
      "|\"cnas9a7\"|  5|[much, memory, ch...|    5|        0|(1024,[52,636,723...|0.07515022047761011|\n",
      "|\"cnas9ae\"|  1|[gotta, get, sett...|    1|        0|(1024,[567,598,62...|0.07515022047761011|\n",
      "|\"cnas9ai\"|  6|           [comment]|    6|        0|  (1024,[910],[1.0])|0.07515022047761011|\n",
      "|\"cnas9aj\"|  1|[pow, right, kisser]|    1|        0|(1024,[386,830,96...| 0.0756647834679763|\n",
      "|\"cnas9av\"|  2|[ultimately, shou...|    2|        0|(1024,[51,208,237...|0.07515022047761011|\n",
      "|\"cnas9b6\"|  1|[ooh, may, right,...|    1|        0|(1024,[125,298,38...|0.07515022047761011|\n",
      "|\"cnas9bf\"|  2|     [fake, seizure]|    2|        0|(1024,[25,568],[1...|0.07515022047761011|\n",
      "|\"cnas9bm\"| 26|        [holy, shit]|   26|        1|(1024,[588,625],[...|0.07970081026058502|\n",
      "|\"cnas9br\"|  2|[really, good, pr...|    2|        0|(1024,[14,88,792]...|0.07515022047761011|\n",
      "|\"cnas9bx\"|  1|[play, heart, gp,...|    1|        0|(1024,[1,28,46,77...|0.07515022047761011|\n",
      "|\"cnas9by\"|  1|[hi, n, nhow, hig...|    1|        0|(1024,[152,306,39...| 0.0812708042677885|\n",
      "|\"cnas9ca\"|  2|    [well, signings]|    2|        0|(1024,[557,641],[...|0.07515022047761011|\n",
      "|\"cnas9cm\"|  2|[guy, dropped, jo...|    2|        0|(1024,[268,646,86...|0.08488974802877589|\n",
      "|\"cnas9cn\"|  1|[week, worth, gro...|    1|        0|(1024,[338,387,39...|0.07515022047761011|\n",
      "|\"cnas9co\"|  1|[edit, found, ans...|    1|        0|(1024,[131,241,73...|0.07515022047761011|\n",
      "|\"cnas9d5\"|  1|[believe, blackli...|    1|        0|(1024,[122,344,64...|0.07515022047761011|\n",
      "|\"cnas9d7\"|  2|[looking, forward...|    2|        0|(1024,[102,123,40...|0.07515022047761011|\n",
      "|\"cnas9d8\"|  0|[max, game, nice,...|    0|        0|(1024,[632,655,74...|0.07412293620282007|\n",
      "|\"cnas9d9\"|  0|[re, getting, bri...|    0|        0|(1024,[170,225,31...| 0.0812708042677885|\n",
      "|\"cnas9dd\"|  1|[ground, types, a...|    1|        0|(1024,[271,361,58...|0.07515022047761011|\n",
      "|\"cnas9dg\"|  1|[gift, keeps, giv...|    1|        0|(1024,[6,197,354]...|0.07515022047761011|\n",
      "|\"cnas9di\"|  0|          [disagree]|    0|        0|  (1024,[448],[1.0])|0.07515022047761011|\n",
      "|\"cnas9dk\"|  1|                  []|    1|        0|        (1024,[],[])|0.07515022047761011|\n",
      "|\"cnas9dq\"|  1|              [nice]|    1|        0|  (1024,[842],[1.0])|0.07412293620282007|\n",
      "|\"cnas9dt\"|  1|[give, us, 200, f...|    1|        0|(1024,[137,193,25...|0.07895911449878874|\n",
      "|\"cnas9du\"| -5|                  []|   -5|        0|        (1024,[],[])|0.07515022047761011|\n",
      "|\"cnas9e0\"|  5|[sounds, like, ai...|    5|        0|(1024,[141,271,34...| 0.0756647834679763|\n",
      "|\"cnas9e5\"|  2|[former, admin, s...|    2|        0|(1024,[20,35,649,...|0.07515022047761011|\n",
      "|\"cnas9em\"|  1|[chance, re, girl...|    1|        0|(1024,[42,352,562...|0.07515022047761011|\n",
      "|\"cnas9eo\"|  1|[mistweaver, monk...|    1|        0|(1024,[0,14,54,15...|0.07515022047761011|\n",
      "|\"cnas9eq\"|  3|            [france]|    3|        0|  (1024,[135],[1.0])|0.07515022047761011|\n",
      "|\"cnas9et\"|  3|[neckbeards, post...|    3|        0|(1024,[130,208,26...|0.08488974802877589|\n",
      "|\"cnas9ew\"|  1|[yet, n, nhttp, y...|    1|        0|(1024,[42,299,391...| 0.0812708042677885|\n",
      "|\"cnas9ez\"| 16| [laser, quest, ___]|   16|        1|(1024,[495,628,98...|0.07515022047761011|\n",
      "|\"cnas9f2\"|  1|          [thoughts]|    1|        0|  (1024,[806],[1.0])|0.07515022047761011|\n",
      "|\"cnas9f7\"|  1|           [oh, god]|    1|        0|(1024,[693,984],[...|0.07515022047761011|\n",
      "|\"cnas9fa\"|  2|[baby, really, ac...|    2|        0|(1024,[14,44,868]...|0.07515022047761011|\n",
      "|\"cnas9fe\"|  2|       [doms, great]|    2|        0|(1024,[116,642],[...|0.07515022047761011|\n",
      "|\"cnas9fg\"|  1|[2gb, version, ca...|    1|        0|(1024,[10,186,424...|0.07515022047761011|\n",
      "|\"cnas9fn\"|  1|         [yes, know]|    1|        0|(1024,[643,835],[...|0.07515022047761011|\n",
      "+---------+---+--------------------+-----+---------+--------------------+-------------------+\n",
      "only showing top 100 rows"
     ]
    }
   ],
   "source": [
    "rfpredictions.show(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31d96bb8638f48f5b665acc7f5249ded",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@timeit\n",
    "def random_forest_regression_filtered(df, featuresCol, labelCol):\n",
    "    '''\n",
    "    Returns a DataFrame containing a column of predicted values of the labelCol.\n",
    "    Predict the output of labelCol using values in featuresCol y = rf(x).\n",
    "    \n",
    "    @params:\n",
    "        df - DataFrame\n",
    "        featuresCol - input features, x\n",
    "        labelCol - output variable, y\n",
    "    '''\n",
    "    \n",
    "    print(df.count())\n",
    "    df = df.filter((df.score >=0) & (df.score <10))\n",
    "    print(df.show(10))\n",
    "    print(df.count())\n",
    "    # split the training and test data using the holdout method\n",
    "    (trainingData, testData) = df.randomSplit([0.8, 0.2])\n",
    "    \n",
    "    # create the random forest regressor, limit number of trees to ten\n",
    "    dtr = RandomForestRegressor(\\\n",
    "       featuresCol=featuresCol, labelCol=labelCol)\n",
    "    \n",
    "    # fit the training data to the regressor to create the model\n",
    "    model = dtr.fit(trainingData)\n",
    "    \n",
    "    # create a DataFrame contained a column with predicted values of the labelCol\n",
    "    predictions = model.transform(testData)\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ce88d216326435db749c33c75a5e805",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "147697364\n",
      "+---------+---+--------------------+-----+---------+--------------------+\n",
      "|       id|ups|      filtered_words|score|viralness|            features|\n",
      "+---------+---+--------------------+-----+---------+--------------------+\n",
      "|\"cnas8zw\"|  3|[mill, career, wa...|    3|        0|(1024,[102,205,31...|\n",
      "|\"cnas8zx\"|  1|[mine, uses, stra...|    1|        0|(1024,[120,423,55...|\n",
      "|\"cnas8zz\"|  2|              [fast]|    2|        0|  (1024,[863],[1.0])|\n",
      "|\"cnas900\"|  6| [guy, professional]|    6|        0|(1024,[931,955],[...|\n",
      "|\"cnas901\"|  1|   [great, question]|    1|        0|(1024,[116,131],[...|\n",
      "|\"cnas902\"|  1|[ie, shiv, ghostb...|    1|        0|(1024,[114,200,36...|\n",
      "|\"cnas903\"|  1|                 [d]|    1|        0|  (1024,[902],[1.0])|\n",
      "|\"cnas905\"|  2|[know, describe, ...|    2|        0|(1024,[47,57,210,...|\n",
      "|\"cnas906\"|  2|           [says, g]|    2|        0|(1024,[34,305],[1...|\n",
      "|\"cnas908\"|  1|       [love, music]|    1|        0|(1024,[112,979],[...|\n",
      "+---------+---+--------------------+-----+---------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "None\n",
      "129748969\n",
      "'random_forest_regression_filtered' took 1838.16 sec\n",
      "\n",
      "Root Mean Squared Error (RMSE) on test data = 1.79043"
     ]
    }
   ],
   "source": [
    "# train random forest regression\n",
    "predictions = random_forest_regression_filtered(df=hashDF,featuresCol=\"features\",labelCol=\"score\")\n",
    "\n",
    "# compute the error\n",
    "evaluator = RegressionEvaluator(labelCol=\"score\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f875470cae3d44d1af1fd255ba993e95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+--------------------+-----+---------+--------------------+------------------+\n",
      "|       id|ups|      filtered_words|score|viralness|            features|        prediction|\n",
      "+---------+---+--------------------+-----+---------+--------------------+------------------+\n",
      "|\"cnas900\"|  6| [guy, professional]|    6|        0|(1024,[931,955],[...|2.0639390632929513|\n",
      "|\"cnas905\"|  2|[know, describe, ...|    2|        0|(1024,[47,57,210,...|2.0471774635344673|\n",
      "|\"cnas90i\"|  1|        [wheredugit]|    1|        0|  (1024,[187],[1.0])|2.0471774635344673|\n",
      "|\"cnas90j\"|  2|[religion, doesn,...|    2|        0|(1024,[50,60,255,...|2.0471774635344673|\n",
      "|\"cnas90z\"|  1|[slightly, strong...|    1|        0|(1024,[561,621,84...|2.0471774635344673|\n",
      "|\"cnas912\"|  3|[ll, try, find, g...|    3|        0|(1024,[95,159,174...|2.0471774635344673|\n",
      "|\"cnas915\"|  4|               [yes]|    4|        0|  (1024,[835],[1.0])|2.0471774635344673|\n",
      "|\"cnas918\"|  3|[haha, guilty, ve...|    3|        0|(1024,[0,150,266,...|2.0891804692630727|\n",
      "|\"cnas919\"|  1|[unfortunately, t...|    1|        0|(1024,[139,513,56...|2.0471774635344673|\n",
      "|\"cnas91e\"|  2|[words, like, awe...|    2|        0|(1024,[386,575,93...|2.0471774635344673|\n",
      "+---------+---+--------------------+-----+---------+--------------------+------------------+\n",
      "only showing top 10 rows"
     ]
    }
   ],
   "source": [
    "predictions.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb4a7b505c9f49a198b3ba98a0a2c457",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.mllib.classification import LogisticRegressionWithLBFGS, LogisticRegressionModel, LogisticRegressionWithSGD\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "@timeit\n",
    "def logistic_regression(df, featuresCol, labelCol):\n",
    "    '''\n",
    "    Returns a DataFrame containing a column of predicted values of the labelCol.\n",
    "    Predict the output of labelCol using values in featuresCol y = rf(x).\n",
    "    \n",
    "    @params:\n",
    "        df - DataFrame\n",
    "        featuresCol - input features, x\n",
    "        labelCol - output variable, y\n",
    "    '''\n",
    "    # split the training and test data using the holdout method\n",
    "    print(df.count())\n",
    "    df = df.filter((df.score >=0) & (df.score <10))\n",
    "    print(df.show(10))\n",
    "    print(df.count())\n",
    "    (trainingData, testData) = df.randomSplit([0.8, 0.2])\n",
    "    \n",
    "    \n",
    "    # TODO: Uncomment the lines below and replace <FILL IN> with appropriate code\n",
    "    # Given hyperparameters\n",
    "    standardization = False\n",
    "    elastic_net_param = 0.8\n",
    "    reg_param = .3\n",
    "    max_iter = 10\n",
    "\n",
    "    lr = (LogisticRegression(featuresCol=featuresCol, labelCol=labelCol, regParam = reg_param, standardization = standardization, maxIter = max_iter,elasticNetParam = elastic_net_param))\n",
    "  \n",
    "    lr_model_basic = lr.fit(trainingData)\n",
    "\n",
    "    trainingSummary = lr_model_basic.summary\n",
    "    accuracy = trainingSummary.accuracy\n",
    "    print(accuracy)\n",
    "    # create a DataFrame contained a column with predicted values of the labelCol\n",
    "    predictions = lr_model_basic.transform(testData)\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4d0f0e47fdc4e1b815a46b38fc3c74c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from pyspark.ml.classification import LogisticRegression\n",
    "# from pyspark.mllib.classification import LogisticRegressionWithLBFGS, LogisticRegressionModel, LogisticRegressionWithSGD\n",
    "# from pyspark.mllib.regression import LabeledPoint\n",
    "@timeit\n",
    "def logistic_regression_viral(df, featuresCol, labelCol):\n",
    "    '''\n",
    "    Returns a DataFrame containing a column of predicted values of the labelCol.\n",
    "    Predict the output of labelCol using values in featuresCol y = rf(x).\n",
    "    \n",
    "    @params:\n",
    "        df - DataFrame\n",
    "        featuresCol - input features, x\n",
    "        labelCol - output variable, y\n",
    "    '''\n",
    "    # split the training and test data using the holdout method\n",
    "#     print(df.count())\n",
    "#     df = df.filter((df.score >=0) & (df.score <10))\n",
    "#     print(df.show(10))\n",
    "#     print(df.count())\n",
    "    (trainingData, testData) = df.randomSplit([0.8, 0.2])\n",
    "    \n",
    "    \n",
    "    # TODO: Uncomment the lines below and replace <FILL IN> with appropriate code\n",
    "    # Given hyperparameters\n",
    "    standardization = False\n",
    "    elastic_net_param = 0.8\n",
    "    reg_param = .3\n",
    "    max_iter = 10\n",
    "\n",
    "    lr = (LogisticRegression(featuresCol=featuresCol, labelCol=labelCol, regParam = reg_param, standardization = standardization, maxIter = max_iter,elasticNetParam = elastic_net_param))\n",
    "  \n",
    "    lr_model_basic = lr.fit(trainingData)\n",
    "\n",
    "    trainingSummary = lr_model_basic.summary\n",
    "    accuracy = trainingSummary.accuracy\n",
    "    print(accuracy)\n",
    "    # create a DataFrame contained a column with predicted values of the labelCol\n",
    "    predictions = lr_model_basic.transform(testData)\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "401555f077ed49718032d726d6ea8844",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "147697364\n",
      "+---------+---+--------------------+-----+---------+--------------------+\n",
      "|       id|ups|      filtered_words|score|viralness|            features|\n",
      "+---------+---+--------------------+-----+---------+--------------------+\n",
      "|\"cnas8zw\"|  3|[mill, career, wa...|    3|        0|(1024,[102,205,31...|\n",
      "|\"cnas8zx\"|  1|[mine, uses, stra...|    1|        0|(1024,[120,423,55...|\n",
      "|\"cnas8zz\"|  2|              [fast]|    2|        0|  (1024,[863],[1.0])|\n",
      "|\"cnas900\"|  6| [guy, professional]|    6|        0|(1024,[931,955],[...|\n",
      "|\"cnas901\"|  1|   [great, question]|    1|        0|(1024,[116,131],[...|\n",
      "|\"cnas902\"|  1|[ie, shiv, ghostb...|    1|        0|(1024,[114,200,36...|\n",
      "|\"cnas903\"|  1|                 [d]|    1|        0|  (1024,[902],[1.0])|\n",
      "|\"cnas905\"|  2|[know, describe, ...|    2|        0|(1024,[47,57,210,...|\n",
      "|\"cnas906\"|  2|           [says, g]|    2|        0|(1024,[34,305],[1...|\n",
      "|\"cnas908\"|  1|       [love, music]|    1|        0|(1024,[112,979],[...|\n",
      "+---------+---+--------------------+-----+---------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "None\n",
      "129748969\n",
      "0.4981577577291075\n",
      "'logistic_regression' took 772.73 sec\n",
      "\n",
      "Root Mean Squared Error (RMSE) on test data = 2.07657"
     ]
    }
   ],
   "source": [
    "# train random forest regression\n",
    "lrpredictions = logistic_regression(df=hashDF,featuresCol=\"features\",labelCol=\"score\")\n",
    "\n",
    "# compute the error\n",
    "evaluator = RegressionEvaluator(labelCol=\"score\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = evaluator.evaluate(lrpredictions)\n",
    "print (\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96d6cb80c6114e62ba10eb3efe7c6846",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+--------------------+-----+---------+--------------------+--------------------+--------------------+----------+\n",
      "|       id|ups|      filtered_words|score|viralness|            features|       rawPrediction|         probability|prediction|\n",
      "+---------+---+--------------------+-----+---------+--------------------+--------------------+--------------------+----------+\n",
      "|\"cnas8zw\"|  3|[mill, career, wa...|    3|        0|(1024,[102,205,31...|[0.04919917672070...|[0.04955881868249...|       1.0|\n",
      "|\"cnas8zx\"|  1|[mine, uses, stra...|    1|        0|(1024,[120,423,55...|[0.04919917672070...|[0.04955881868249...|       1.0|\n",
      "|\"cnas900\"|  6| [guy, professional]|    6|        0|(1024,[931,955],[...|[0.04919917672070...|[0.04955881868249...|       1.0|\n",
      "|\"cnas90a\"|  2|[always, forget, ...|    2|        0|(1024,[119,277,46...|[0.04919917672070...|[0.04955881868249...|       1.0|\n",
      "|\"cnas90e\"|  1|[haha, awesome, m...|    1|        0|(1024,[342,537,55...|[0.04919917672070...|[0.04955881868249...|       1.0|\n",
      "|\"cnas90f\"|  3|[completely, agre...|    3|        0|(1024,[1,60,392,4...|[0.04919917672070...|[0.04955881868249...|       1.0|\n",
      "|\"cnas90n\"|  7|[math, prof, does...|    7|        0|(1024,[60,126,748...|[0.04919917672070...|[0.04955881868249...|       1.0|\n",
      "|\"cnas90s\"|  2|             [thank]|    2|        0|  (1024,[362],[1.0])|[0.04919917672070...|[0.04955881868249...|       1.0|\n",
      "|\"cnas90t\"|  1|[chappelle, https...|    1|        0|(1024,[257,322,38...|[0.04919917672070...|[0.04955881868249...|       1.0|\n",
      "|\"cnas914\"|  1|        [like, idea]|    1|        0|(1024,[386,726],[...|[0.04919917672070...|[0.04955881868249...|       1.0|\n",
      "|\"cnas917\"|  2|[hellohuman, ms, ...|    2|        0|(1024,[71,139,688...|[0.04919917672070...|[0.04955881868249...|       1.0|\n",
      "|\"cnas91c\"|  1|    [dodge, rampage]|    1|        0|(1024,[315,920],[...|[0.04919917672070...|[0.04955881868249...|       1.0|\n",
      "|\"cnas91g\"|  2|[health, insuranc...|    2|        0|(1024,[25,63,325,...|[0.04919917672070...|[0.04955881868249...|       1.0|\n",
      "|\"cnas91l\"|  1|       [re, talking]|    1|        0|(1024,[984,985],[...|[0.04919917672070...|[0.04955881868249...|       1.0|\n",
      "|\"cnas91n\"|  5|[mic, city, sons,...|    5|        0|(1024,[14,26,40,1...|[0.04919917672070...|[0.04955881868249...|       1.0|\n",
      "|\"cnas91r\"|  1|      [karina, hart]|    1|        0|(1024,[218,819],[...|[0.04919917672070...|[0.04955881868249...|       1.0|\n",
      "|\"cnas91s\"|  1|[thanks, nye, mak...|    1|        0|(1024,[150,530,60...|[0.04919917672070...|[0.04955881868249...|       1.0|\n",
      "|\"cnas91v\"|  1|[really, wish, co...|    1|        0|(1024,[14,239,272...|[0.04919917672070...|[0.04955881868249...|       1.0|\n",
      "|\"cnas927\"|  3|[ve, always, wond...|    3|        0|(1024,[40,228,277...|[0.04919917672070...|[0.04955881868249...|       1.0|\n",
      "|\"cnas92e\"|  9|[didn, really, ma...|    9|        0|(1024,[14,629,645...|[0.04919917672070...|[0.04955881868249...|       1.0|\n",
      "|\"cnas92g\"|  3|[tough, question,...|    3|        0|(1024,[77,131,156...|[0.04919917672070...|[0.04955881868249...|       1.0|\n",
      "|\"cnas92h\"|  2|[really, awesome,...|    2|        0|(1024,[14,252,405...|[0.04919917672070...|[0.04955881868249...|       1.0|\n",
      "|\"cnas930\"|  3|           [gilbert]|    3|        0|  (1024,[556],[1.0])|[0.04919917672070...|[0.04955881868249...|       1.0|\n",
      "|\"cnas931\"|  1|[1, 5, 1, 2, vers...|    1|        0|(1024,[62,85,354,...|[0.04919917672070...|[0.04955881868249...|       1.0|\n",
      "|\"cnas935\"|  1|            [thanks]|    1|        0|  (1024,[606],[1.0])|[0.04919917672070...|[0.04955881868249...|       1.0|\n",
      "|\"cnas93b\"|  1|[noticed, someone...|    1|        0|(1024,[5,53,72,20...|[0.04919917672070...|[0.04955881868249...|       1.0|\n",
      "|\"cnas93i\"|  1|[ll, throw, cats,...|    1|        0|(1024,[159,270,32...|[0.04919917672070...|[0.04955881868249...|       1.0|\n",
      "|\"cnas93j\"|  1|[mean, blonde, lo...|    1|        0|(1024,[101,278,63...|[0.04919917672070...|[0.04955881868249...|       1.0|\n",
      "|\"cnas93x\"|  2|[picture, lost, b...|    2|        0|(1024,[405,638,72...|[0.04919917672070...|[0.04955881868249...|       1.0|\n",
      "|\"cnas93z\"|  0|[whatever, missio...|    0|        0|(1024,[34,79,131,...|[0.04919917672070...|[0.04955881868249...|       1.0|\n",
      "|\"cnas940\"|  1|    [add, jsu, zack]|    1|        0|(1024,[75,451,624...|[0.04919917672070...|[0.04955881868249...|       1.0|\n",
      "|\"cnas94o\"|  7|[bugs, ve, notice...|    7|        0|(1024,[1,14,130,3...|[0.04919917672070...|[0.04955881868249...|       1.0|\n",
      "|\"cnas94y\"|  1|[romans, 7, 17, e...|    1|        0|(1024,[39,101,174...|[0.04919917672070...|[0.04955881868249...|       1.0|\n",
      "|\"cnas959\"|  1|[steam, support, ...|    1|        0|(1024,[64,602,679...|[0.04919917672070...|[0.04955881868249...|       1.0|\n",
      "|\"cnas95a\"|  1|[imagine, saying,...|    1|        0|(1024,[47,196,439...|[0.04919917672070...|[0.04955881868249...|       1.0|\n",
      "|\"cnas95i\"|  2|[okay, totally, b...|    2|        0|(1024,[19,21,29,6...|[0.04919917672070...|[0.04955881868249...|       1.0|\n",
      "|\"cnas95r\"|  3|[ve, stuck, coval...|    3|        0|(1024,[63,113,161...|[0.04919917672070...|[0.04955881868249...|       1.0|\n",
      "|\"cnas95t\"|  1|[hadn, realized, ...|    1|        0|(1024,[140,234,30...|[0.04919917672070...|[0.04955881868249...|       1.0|\n",
      "|\"cnas962\"|  4|[m, sure, believe...|    4|        0|(1024,[262,408,47...|[0.04919917672070...|[0.04955881868249...|       1.0|\n",
      "|\"cnas969\"|  1|[freaking, sweet,...|    1|        0|(1024,[484,606,99...|[0.04919917672070...|[0.04955881868249...|       1.0|\n",
      "|\"cnas96b\"|  1|           [welcome]|    1|        0|  (1024,[317],[1.0])|[0.04919917672070...|[0.04955881868249...|       1.0|\n",
      "|\"cnas96e\"|  7|[one, harris, bro...|    7|        0|(1024,[10,40,60,1...|[0.04919917672070...|[0.04955881868249...|       1.0|\n",
      "|\"cnas96j\"|  8|         [hey, guys]|    8|        0|(1024,[0,594],[1....|[0.04919917672070...|[0.04955881868249...|       1.0|\n",
      "|\"cnas971\"|  3|[looks, like, cus...|    3|        0|(1024,[37,101,125...|[0.04919917672070...|[0.04955881868249...|       1.0|\n",
      "|\"cnas97u\"|  3|               [hey]|    3|        0|  (1024,[594],[1.0])|[0.04919917672070...|[0.04955881868249...|       1.0|\n",
      "|\"cnas97y\"|  3|                  []|    3|        0|        (1024,[],[])|[0.04919917672070...|[0.04955881868249...|       1.0|\n",
      "|\"cnas97z\"|  3|[downvoted, bad, ...|    3|        0|(1024,[187,299,34...|[0.04919917672070...|[0.04955881868249...|       1.0|\n",
      "|\"cnas987\"|  1|[sailed, across, ...|    1|        0|(1024,[200,378,51...|[0.04919917672070...|[0.04955881868249...|       1.0|\n",
      "|\"cnas98g\"|  0|[call, bullshit, ...|    0|        0|(1024,[31,138,205...|[0.04919917672070...|[0.04955881868249...|       1.0|\n",
      "|\"cnas991\"|  2|        [think, bad]|    2|        0|(1024,[382,396],[...|[0.04919917672070...|[0.04955881868249...|       1.0|\n",
      "|\"cnas997\"|  1|[hello, steam, 3,...|    1|        0|(1024,[6,95,100,1...|[0.04919917672070...|[0.04955881868249...|       1.0|\n",
      "|\"cnas99f\"|  2|[playstyle, well,...|    2|        0|(1024,[557,731,85...|[0.04919917672070...|[0.04955881868249...|       1.0|\n",
      "|\"cnas9a4\"|  1|[name, gonna, bli...|    1|        0|(1024,[101,257,30...|[0.04919917672070...|[0.04955881868249...|       1.0|\n",
      "|\"cnas9ab\"|  2|[post, tracks, be...|    2|        0|(1024,[139,253,39...|[0.04919917672070...|[0.04955881868249...|       1.0|\n",
      "|\"cnas9am\"|  4|[think, care, lot...|    4|        0|(1024,[60,231,264...|[0.04919917672070...|[0.04955881868249...|       1.0|\n",
      "|\"cnas9ao\"|  2|[would, love, hir...|    2|        0|(1024,[112,130,25...|[0.04919917672070...|[0.04955881868249...|       1.0|\n",
      "|\"cnas9au\"|  1|[dude, like, 3, c...|    1|        0|(1024,[386,597,72...|[0.04919917672070...|[0.04955881868249...|       1.0|\n",
      "|\"cnas9av\"|  2|[ultimately, shou...|    2|        0|(1024,[51,208,237...|[0.04919917672070...|[0.04955881868249...|       1.0|\n",
      "|\"cnas9ax\"|  1|              [well]|    1|        0|  (1024,[557],[1.0])|[0.04919917672070...|[0.04955881868249...|       1.0|\n",
      "|\"cnas9b9\"|  4|[wouldnt, smart, ...|    4|        0|(1024,[303,441,44...|[0.04919917672070...|[0.04955881868249...|       1.0|\n",
      "|\"cnas9bf\"|  2|     [fake, seizure]|    2|        0|(1024,[25,568],[1...|[0.04919917672070...|[0.04955881868249...|       1.0|\n",
      "|\"cnas9bs\"|  3|[great, article, ...|    3|        0|(1024,[12,116,310...|[0.04919917672070...|[0.04955881868249...|       1.0|\n",
      "|\"cnas9c3\"|  1|[interesting, tho...|    1|        0|(1024,[241,606,81...|[0.04919917672070...|[0.04955881868249...|       1.0|\n",
      "|\"cnas9cq\"|  1|       [e39, though]|    1|        0|(1024,[209,731],[...|[0.04919917672070...|[0.04955881868249...|       1.0|\n",
      "|\"cnas9ct\"|  2|[m, spending, sec...|    2|        0|(1024,[26,39,48,9...|[0.04919917672070...|[0.04955881868249...|       1.0|\n",
      "|\"cnas9cw\"|  4|              [woah]|    4|        0|  (1024,[190],[1.0])|[0.04919917672070...|[0.04955881868249...|       1.0|\n",
      "|\"cnas9d0\"|  1|[thank, ll, take,...|    1|        0|(1024,[159,343,36...|[0.04919917672070...|[0.04955881868249...|       1.0|\n",
      "|\"cnas9d1\"|  1|[correct, answer,...|    1|        0|(1024,[32,147,202...|[0.04919917672070...|[0.04955881868249...|       1.0|\n",
      "|\"cnas9d4\"|  2|[think, fixed, heat]|    2|        0|(1024,[326,371,39...|[0.04919917672070...|[0.04955881868249...|       1.0|\n",
      "|\"cnas9d7\"|  2|[looking, forward...|    2|        0|(1024,[102,123,40...|[0.04919917672070...|[0.04955881868249...|       1.0|\n",
      "|\"cnas9da\"|  1|[31st, dec, 1st, ...|    1|        0|(1024,[21,141,277...|[0.04919917672070...|[0.04955881868249...|       1.0|\n",
      "|\"cnas9e6\"|  2|        [u, tandem7]|    2|        0|(1024,[932,982],[...|[0.04919917672070...|[0.04955881868249...|       1.0|\n",
      "|\"cnas9e7\"|  1|     [yep, mid, 30s]|    1|        0|(1024,[14,764,857...|[0.04919917672070...|[0.04955881868249...|       1.0|\n",
      "|\"cnas9ea\"|  1|[m, might, back, ...|    1|        0|(1024,[174,345,37...|[0.04919917672070...|[0.04955881868249...|       1.0|\n",
      "|\"cnas9ej\"|  1|[big, boy, steamt...|    1|        0|(1024,[170,310,47...|[0.04919917672070...|[0.04955881868249...|       1.0|\n",
      "|\"cnas9eu\"|  1|               [yes]|    1|        0|  (1024,[835],[1.0])|[0.04919917672070...|[0.04955881868249...|       1.0|\n",
      "|\"cnas9ev\"|  1|[yeah, uncle, did...|    1|        0|(1024,[131,145,18...|[0.04919917672070...|[0.04955881868249...|       1.0|\n",
      "|\"cnas9fk\"|  1|[greatest, thing,...|    1|        0|(1024,[66,502,519...|[0.04919917672070...|[0.04955881868249...|       1.0|\n",
      "|\"cnas9fu\"|  1|[histogram, karma...|    1|        0|(1024,[3,4,7,10,1...|[0.04919917672070...|[0.04955881868249...|       1.0|\n",
      "|\"cnas9g3\"|  2|[roaring, 20, wou...|    2|        0|(1024,[120,259,62...|[0.04919917672070...|[0.04955881868249...|       1.0|\n",
      "|\"cnas9g4\"|  1|  [thanks, purchase]|    1|        0|(1024,[72,606],[1...|[0.04919917672070...|[0.04955881868249...|       1.0|\n",
      "|\"cnas9gf\"|  2|               [yes]|    2|        0|  (1024,[835],[1.0])|[0.04919917672070...|[0.04955881868249...|       1.0|\n",
      "|\"cnas9gh\"|  1|[true, thanks, re...|    1|        0|(1024,[261,323,34...|[0.04919917672070...|[0.04955881868249...|       1.0|\n",
      "|\"cnas9gt\"|  6|[could, get, clip...|    6|        0|(1024,[259,308,30...|[0.04919917672070...|[0.04955881868249...|       1.0|\n",
      "|\"cnas9h3\"|  1|[melee, falco, n,...|    1|        0|(1024,[5,18,19,31...|[0.04919917672070...|[0.04955881868249...|       1.0|\n",
      "|\"cnas9h6\"|  0|       [youre, hero]|    0|        0|(1024,[192,764],[...|[0.04919917672070...|[0.04955881868249...|       1.0|\n",
      "|\"cnas9hl\"|  1|[yes, 7680x1440, ...|    1|        0|(1024,[85,112,289...|[0.04919917672070...|[0.04955881868249...|       1.0|\n",
      "|\"cnas9hr\"|  1|[looks, great, ni...|    1|        0|(1024,[101,116,55...|[0.04919917672070...|[0.04955881868249...|       1.0|\n",
      "|\"cnas9hs\"|  7|[really, said, ev...|    7|        0|(1024,[5,14,16,25...|[0.04919917672070...|[0.04955881868249...|       1.0|\n",
      "|\"cnas9i6\"|  1|[foxit, pdf, reader]|    1|        0|(1024,[131,149,16...|[0.04919917672070...|[0.04955881868249...|       1.0|\n",
      "|\"cnas9i9\"|  2|[looks, like, r, ...|    2|        0|(1024,[101,226,38...|[0.04919917672070...|[0.04955881868249...|       1.0|\n",
      "|\"cnas9if\"|  1|[seconding, trade...|    1|        0|(1024,[187,461,59...|[0.04919917672070...|[0.04955881868249...|       1.0|\n",
      "|\"cnas9iq\"|  1|[yeah, sure, ll, ...|    1|        0|(1024,[145,159,24...|[0.04919917672070...|[0.04955881868249...|       1.0|\n",
      "|\"cnas9j6\"|  0|        [australian]|    0|        0|  (1024,[964],[1.0])|[0.04919917672070...|[0.04955881868249...|       1.0|\n",
      "|\"cnas9jd\"|  2|              [yeah]|    2|        0|  (1024,[145],[1.0])|[0.04919917672070...|[0.04955881868249...|       1.0|\n",
      "|\"cnas9jo\"|  2|[sea, cow, sea, c...|    2|        0|(1024,[544,575,66...|[0.04919917672070...|[0.04955881868249...|       1.0|\n",
      "|\"cnas9k8\"|  1|        [struggling]|    1|        0|   (1024,[15],[1.0])|[0.04919917672070...|[0.04955881868249...|       1.0|\n",
      "|\"cnas9kd\"|  0|[friends, m, alco...|    0|        0|(1024,[169,186,47...|[0.04919917672070...|[0.04955881868249...|       1.0|\n",
      "|\"cnas9ki\"|  1|  [left, get, money]|    1|        0|(1024,[430,442,56...|[0.04919917672070...|[0.04955881868249...|       1.0|\n",
      "|\"cnas9kn\"|  1|              [hard]|    1|        0|  (1024,[389],[1.0])|[0.04919917672070...|[0.04955881868249...|       1.0|\n",
      "+---------+---+--------------------+-----+---------+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 100 rows"
     ]
    }
   ],
   "source": [
    "lrpredictions.show(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab886458a4e54896876f2f66f3a19ae2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9229822832333946\n",
      "'logistic_regression_viral' took 578.81 sec\n",
      "\n",
      "Root Mean Squared Error (RMSE) on test data = 0.277614"
     ]
    }
   ],
   "source": [
    "# train random forest regression\n",
    "lrViralpredictions = logistic_regression_viral(df=hashDF,featuresCol=\"features\",labelCol=\"viralness\")\n",
    "\n",
    "# compute the error\n",
    "evaluator = RegressionEvaluator(labelCol=\"viralness\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = evaluator.evaluate(lrViralpredictions)\n",
    "print (\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa66340915f349baa18d576f19056592",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+--------------------+-----+---------+--------------------+--------------------+--------------------+----------+\n",
      "|       id|ups|      filtered_words|score|viralness|            features|       rawPrediction|         probability|prediction|\n",
      "+---------+---+--------------------+-----+---------+--------------------+--------------------+--------------------+----------+\n",
      "|\"cnas901\"|  1|   [great, question]|    1|        0|(1024,[116,131],[...|[2.48357455628972...|[0.92298228323339...|       0.0|\n",
      "|\"cnas903\"|  1|                 [d]|    1|        0|  (1024,[902],[1.0])|[2.48357455628972...|[0.92298228323339...|       0.0|\n",
      "|\"cnas906\"|  2|           [says, g]|    2|        0|(1024,[34,305],[1...|[2.48357455628972...|[0.92298228323339...|       0.0|\n",
      "|\"cnas90f\"|  3|[completely, agre...|    3|        0|(1024,[1,60,392,4...|[2.48357455628972...|[0.92298228323339...|       0.0|\n",
      "|\"cnas90j\"|  2|[religion, doesn,...|    2|        0|(1024,[50,60,255,...|[2.48357455628972...|[0.92298228323339...|       0.0|\n",
      "|\"cnas90k\"|  2|        [hey, rocky]|    2|        0|(1024,[594,724],[...|[2.48357455628972...|[0.92298228323339...|       0.0|\n",
      "|\"cnas913\"|  2|        [love, okay]|    2|        0|(1024,[112,490],[...|[2.48357455628972...|[0.92298228323339...|       0.0|\n",
      "|\"cnas914\"|  1|        [like, idea]|    1|        0|(1024,[386,726],[...|[2.48357455628972...|[0.92298228323339...|       0.0|\n",
      "|\"cnas916\"|  0|[wish, google, dr...|    0|        0|(1024,[35,239,249...|[2.48357455628972...|[0.92298228323339...|       0.0|\n",
      "|\"cnas91d\"|  1|[one, kill, pirat...|    1|        0|(1024,[49,87,250,...|[2.48357455628972...|[0.92298228323339...|       0.0|\n",
      "+---------+---+--------------------+-----+---------+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 10 rows"
     ]
    }
   ],
   "source": [
    "lrViralpredictions.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 2
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
