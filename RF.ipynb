{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cd840dc6feb40949816a2176cfd5a86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>2</td><td>application_1606879370951_0003</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-172-31-86-160.ec2.internal:20888/proxy/application_1606879370951_0003/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-172-31-89-190.ec2.internal:8042/node/containerlogs/container_1606879370951_0003_01_000001/livy\">Link</a></td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from pyspark.ml.linalg import SparseVector\n",
    "from pyspark.sql.functions import explode\n",
    "from pyspark import SparkFiles\n",
    "from pyspark.sql import Row\n",
    "\n",
    "import bz2\n",
    "import json\n",
    "import time\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import * # CountVectorizer, Tokenizer, RegexTokenizer, HashingTF\n",
    "from pyspark.ml.regression import * # RandomForestRegressor, LinearRegression, DecisionTreeRegressor\n",
    "from pyspark.ml.evaluation import RegressionEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7dfbfe88a1540d6af459443a28a7d38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def timeit(method):\n",
    "    '''\n",
    "    Decorator to time functions.\n",
    "    '''\n",
    "    def timed(*args, **kw):\n",
    "        ts = time.time()\n",
    "        result = method(*args, **kw)\n",
    "        te = time.time()\n",
    "\n",
    "        print('%r took %2.2f sec\\n' % (method.__name__, te-ts))\n",
    "              \n",
    "        return result\n",
    "    return timed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1ccb059698a4fb29e654265d4779504",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@timeit\n",
    "def load_data(filename, test=True, mb=1):\n",
    "    '''\n",
    "    Returns either the a DataFrame containing all the tweets or a test DataFrame containing\n",
    "    numTest comments.\n",
    "    \n",
    "    @params:\n",
    "        test - boolean, if True return test DataFrame\n",
    "        mb - the number of megabytes to load from the data set\n",
    "    '''\n",
    "    \n",
    "    # load compressed file\n",
    "    #comments_file = bz2.BZ2File(filename, \"r\")\n",
    "    \n",
    "    # convert the megabytes to bytes\n",
    "    #size = mb * (1024 ** 2)\n",
    "    \n",
    "    # load a test dataset of size mb\n",
    "    if test:\n",
    "        # create RDD using string returned by reading the comments file\n",
    "        # specify bytesize of file to read\n",
    "        #commentRDD = sc.parallelize(comments_file.readlines(size))\n",
    "        #commentRDD = sc.parallelize(filename)\n",
    "        # read RDD as json and convert to a DataFrame\n",
    "        df = spark.read.json(filename)\n",
    "    # load full dataset\n",
    "    else:\n",
    "        df = spark.read.json(filename)\n",
    "        \n",
    "    # return a new DataFrame that doesn't contain deleted comments\n",
    "    #return df.filter(\"body != '[deleted]'\")\n",
    "    return df.filter(\"body != '[deleted]'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f58dbfe314d41fd92f762ee46582a8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'load_data' took 66.84 sec\n",
      "\n",
      "Snippet of Comment DataFrame:\n",
      "+--------------------+---+-----+------+--------------+-----+\n",
      "|                body|ups|downs|gilded|     subreddit|score|\n",
      "+--------------------+---+-----+------+--------------+-----+\n",
      "|Most of us have s...| 14|    0|     0|      exmormon|   14|\n",
      "|But Mill's career...|  3|    0|     0|CanadaPolitics|    3|\n",
      "|Mine uses a strai...|  1|    0|     0| AdviceAnimals|    1|\n",
      "|Very fast, thank ...|  2|    0|     0|    freedonuts|    2|\n",
      "|The guy is a prof...|  6|    0|     0|           WTF|    6|\n",
      "+--------------------+---+-----+------+--------------+-----+\n",
      "only showing top 5 rows\n",
      "\n",
      "Column names of comment DataFrame:\n",
      "['approved_by', 'archived', 'author', 'author_flair_css_class', 'author_flair_text', 'banned_by', 'body', 'body_html', 'controversiality', 'created', 'created_utc', 'distinguished', 'downs', 'edited', 'gilded', 'id', 'likes', 'link_id', 'mod_reports', 'name', 'num_reports', 'parent_id', 'removal_reason', 'replies', 'report_reasons', 'retrieved_on', 'saved', 'score', 'score_hidden', 'subreddit', 'subreddit_id', 'ups', 'user_reports']\n",
      "\n",
      "The total number of comments: 147697374 (deleted comments removed)"
     ]
    }
   ],
   "source": [
    "filename = 's3://dsml-vasu-simar-daniel/RC_2015-0*'\n",
    "\n",
    "# load the comments into a DataFrame\n",
    "commentDF = load_data(filename, mb=1)\n",
    "\n",
    "# Display comments and information\n",
    "print(\"Snippet of Comment DataFrame:\")\n",
    "commentDF.select('body', 'ups', 'downs', 'gilded', 'subreddit', 'score').show(5)\n",
    "print(\"Column names of comment DataFrame:\")\n",
    "print(commentDF.columns)\n",
    "print(\"\\nThe total number of comments: %s (deleted comments removed)\" % commentDF.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32cc50eac8f441c1b8cd5cc4cdc917b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+--------------------+-----+\n",
      "|     id|ups|                body|score|\n",
      "+-------+---+--------------------+-----+\n",
      "|cnas8zv| 14|Most of us have s...|   14|\n",
      "|cnas8zw|  3|But Mill's career...|    3|\n",
      "|cnas8zx|  1|Mine uses a strai...|    1|\n",
      "|cnas8zz|  2|Very fast, thank ...|    2|\n",
      "|cnas900|  6|The guy is a prof...|    6|\n",
      "+-------+---+--------------------+-----+\n",
      "only showing top 5 rows"
     ]
    }
   ],
   "source": [
    "sentenceDF = commentDF.select('id','ups','body','score')\n",
    "sentenceDF.show(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50c6ae8ab65447b096f8a1446e2e26f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# use pyspark tokenizer object to split words in array\n",
    "pattern = \"\\\\W\"\n",
    "# tokenizer = RegexTokenizer(inputCol=\"body\", outputCol=\"words\", pattern=pattern)\n",
    "tokenizer = Tokenizer(inputCol=\"body\", outputCol=\"words\")\n",
    "wordsDF = tokenizer.transform(sentenceDF)\n",
    "\n",
    "# Remove stop words\n",
    "remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered_words\")\n",
    "wordsFilteredDF = remover.transform(wordsDF)\n",
    "\n",
    "# Remove body and words since they will no longer be used\n",
    "wordsFilteredDF = wordsFilteredDF.select('id','ups','filtered_words','score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01c8416ec03a4ef1af9216052240baee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@timeit\n",
    "def term_frequency(df, inputCol, outputCol, hashFeatures=None):\n",
    "    '''\n",
    "    Returns a DataFrame object containing a new row with the extracted features. \n",
    "    Passing hashed=True will return a Featured Hashed matrix.\n",
    "    \n",
    "    @params:\n",
    "        df - DataFrame\n",
    "        inputCol - name of input column from DataFrame to find features\n",
    "        outputCol - name of the column to save the features\n",
    "        hashFeatures - number of features for HashingTF, if None will perform \n",
    "            CountVectorization\n",
    "    '''\n",
    "    \n",
    "    # since the number of features was not passed perform standard CountVectorization\n",
    "    if hashFeatures is None:\n",
    "        cv = CountVectorizer(inputCol=inputCol, outputCol=outputCol)\n",
    "        feature_extractor = cv.fit(wordsFilteredDF)\n",
    "    # otherwise perform a feature extractor with \n",
    "    else:\n",
    "        feature_extractor = HashingTF(\\\n",
    "                              inputCol=inputCol, outputCol=outputCol, numFeatures=hashFeatures)\n",
    "    \n",
    "    # create a new DataFrame using either feature extraction method\n",
    "    return feature_extractor.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cf396145ffb4ce19a98ef186d7481bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'term_frequency' took 0.07 sec\n",
      "\n",
      "+--------------------+--------------------+\n",
      "|      filtered_words|            features|\n",
      "+--------------------+--------------------+\n",
      "|[us, family, memb...|(1024,[368,386,45...|\n",
      "|[mill's, career, ...|(1024,[102,211,22...|\n",
      "|[mine, uses, stra...|(1024,[112,120,18...|\n",
      "|[fast,, thank, you!]|(1024,[206,220,36...|\n",
      "|[guy, professiona...|(1024,[95,358,366...|\n",
      "+--------------------+--------------------+\n",
      "only showing top 5 rows"
     ]
    }
   ],
   "source": [
    "# Feature Hash the comment content\n",
    "# number of features for Feature Hash matrix, reccomended too use power of 2\n",
    "hashDF = term_frequency(\\\n",
    "    df=wordsFilteredDF, inputCol=\"filtered_words\", outputCol=\"features\", hashFeatures=1024)\n",
    "\n",
    "# Display snippet of new DataFrame\n",
    "hashDF.select('filtered_words','features').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "daf3d7c258c34789a48838634c41b435",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@timeit\n",
    "def random_forest_regression(df, featuresCol, labelCol):\n",
    "    '''\n",
    "    Returns a DataFrame containing a column of predicted values of the labelCol.\n",
    "    Predict the output of labelCol using values in featuresCol y = rf(x).\n",
    "    \n",
    "    @params:\n",
    "        df - DataFrame\n",
    "        featuresCol - input features, x\n",
    "        labelCol - output variable, y\n",
    "    '''\n",
    "    # split the training and test data using the holdout method\n",
    "    (trainingData, testData) = df.randomSplit([0.8, 0.2])\n",
    "    \n",
    "    # create the random forest regressor, limit number of trees to ten\n",
    "    dtr = RandomForestRegressor(\\\n",
    "       featuresCol=featuresCol, labelCol=labelCol)\n",
    "    \n",
    "    # fit the training data to the regressor to create the model\n",
    "    model = dtr.fit(trainingData)\n",
    "    \n",
    "    # create a DataFrame contained a column with predicted values of the labelCol\n",
    "    predictions = model.transform(testData)\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec0583ad45ab4bec887f6483d0e34e9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5db9ea66fd854d9a8bd96c7413766127",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# train random forest regression\n",
    "predictions = random_forest_regression(df=hashDF,featuresCol=\"features\",labelCol=\"score\")\n",
    "\n",
    "# compute the error\n",
    "evaluator = RegressionEvaluator(labelCol=\"score\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.show(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 2
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
