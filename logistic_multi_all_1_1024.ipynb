{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34d988c6f5b64275bb50df88f80d0620",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from pyspark.ml.linalg import SparseVector\n",
    "from pyspark.sql.functions import explode\n",
    "from pyspark import SparkFiles\n",
    "from pyspark.sql import Row\n",
    "\n",
    "import bz2\n",
    "import json\n",
    "import time\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import * # CountVectorizer, Tokenizer, RegexTokenizer, HashingTF\n",
    "from pyspark.ml.regression import * # RandomForestRegressor, LinearRegression, DecisionTreeRegressor\n",
    "from pyspark.ml.evaluation import RegressionEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67b8eaefed704863949dc0dee6a298e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def timeit(method):\n",
    "    '''\n",
    "    Decorator to time functions.\n",
    "    '''\n",
    "    def timed(*args, **kw):\n",
    "        ts = time.time()\n",
    "        result = method(*args, **kw)\n",
    "        te = time.time()\n",
    "\n",
    "        print('%r took %2.2f sec\\n' % (method.__name__, te-ts))\n",
    "              \n",
    "        return result\n",
    "    return timed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcf13aefa79d421c811a35a57c440f41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@timeit\n",
    "def load_data(filename, test=True, mb=1):\n",
    "    '''\n",
    "    Returns either the a DataFrame containing all the tweets or a test DataFrame containing\n",
    "    numTest comments.\n",
    "    \n",
    "    @params:\n",
    "        test - boolean, if True return test DataFrame\n",
    "        mb - the number of megabytes to load from the data set\n",
    "    '''\n",
    "    \n",
    "    # load compressed file\n",
    "    #comments_file = bz2.BZ2File(filename, \"r\")\n",
    "    \n",
    "    # convert the megabytes to bytes\n",
    "    #size = mb * (1024 ** 2)\n",
    "    \n",
    "    # load a test dataset of size mb\n",
    "    if test:\n",
    "        # create RDD using string returned by reading the comments file\n",
    "        # specify bytesize of file to read\n",
    "        #commentRDD = sc.parallelize(comments_file.readlines(size))\n",
    "        #commentRDD = sc.parallelize(filename)\n",
    "        # read RDD as json and convert to a DataFrame\n",
    "        df = spark.read.json(filename)\n",
    "    # load full dataset\n",
    "    else:\n",
    "        df = spark.read.json(filename)\n",
    "        \n",
    "    # return a new DataFrame that doesn't contain deleted comments\n",
    "    #return df.filter(\"body != '[deleted]'\")\n",
    "    return df.filter(\"body != '[deleted]'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7057bb1ff194930985ae9f60ece730d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'load_data' took 81.39 sec\n",
      "\n",
      "Snippet of Comment DataFrame:\n",
      "+--------------------+---+-----+------+--------------+-----+\n",
      "|                body|ups|downs|gilded|     subreddit|score|\n",
      "+--------------------+---+-----+------+--------------+-----+\n",
      "|Most of us have s...| 14|    0|     0|      exmormon|   14|\n",
      "|But Mill's career...|  3|    0|     0|CanadaPolitics|    3|\n",
      "|Mine uses a strai...|  1|    0|     0| AdviceAnimals|    1|\n",
      "|Very fast, thank ...|  2|    0|     0|    freedonuts|    2|\n",
      "|The guy is a prof...|  6|    0|     0|           WTF|    6|\n",
      "+--------------------+---+-----+------+--------------+-----+\n",
      "only showing top 5 rows\n",
      "\n",
      "Column names of comment DataFrame:\n",
      "['approved_by', 'archived', 'author', 'author_flair_css_class', 'author_flair_text', 'banned_by', 'body', 'body_html', 'controversiality', 'created', 'created_utc', 'distinguished', 'downs', 'edited', 'gilded', 'id', 'likes', 'link_id', 'mod_reports', 'name', 'num_reports', 'parent_id', 'removal_reason', 'replies', 'report_reasons', 'retrieved_on', 'saved', 'score', 'score_hidden', 'subreddit', 'subreddit_id', 'ups', 'user_reports']\n",
      "\n",
      "The total number of comments: 147697374 (deleted comments removed)"
     ]
    }
   ],
   "source": [
    "filename = 's3://dsml-vasu-simar-daniel/RC_2015-0*'\n",
    "\n",
    "# load the comments into a DataFrame\n",
    "commentDF = load_data(filename, mb=1)\n",
    "\n",
    "# Display comments and information\n",
    "print(\"Snippet of Comment DataFrame:\")\n",
    "commentDF.select('body', 'ups', 'downs', 'gilded', 'subreddit', 'score').show(5)\n",
    "print(\"Column names of comment DataFrame:\")\n",
    "print(commentDF.columns)\n",
    "print(\"\\nThe total number of comments: %s (deleted comments removed)\" % commentDF.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a83148bfa28f4a958148cc6f0f80fd8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+--------------------+-----+\n",
      "|     id|ups|                body|score|\n",
      "+-------+---+--------------------+-----+\n",
      "|cnas8zv| 14|Most of us have s...|   14|\n",
      "|cnas8zw|  3|But Mill's career...|    3|\n",
      "|cnas8zx|  1|Mine uses a strai...|    1|\n",
      "|cnas8zz|  2|Very fast, thank ...|    2|\n",
      "|cnas900|  6|The guy is a prof...|    6|\n",
      "+-------+---+--------------------+-----+\n",
      "only showing top 5 rows"
     ]
    }
   ],
   "source": [
    "sentenceDF = commentDF.select('id','ups','body','score')\n",
    "sentenceDF.show(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0823e20d1c534384b71e85631c4de5d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# use pyspark tokenizer object to split words in array\n",
    "pattern = \"\\\\W\"\n",
    "# tokenizer = RegexTokenizer(inputCol=\"body\", outputCol=\"words\", pattern=pattern)\n",
    "tokenizer = Tokenizer(inputCol=\"body\", outputCol=\"words\")\n",
    "wordsDF = tokenizer.transform(sentenceDF)\n",
    "\n",
    "# Remove stop words\n",
    "remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered_words\")\n",
    "wordsFilteredDF = remover.transform(wordsDF)\n",
    "\n",
    "# Remove body and words since they will no longer be used\n",
    "wordsFilteredDF = wordsFilteredDF.select('id','ups','filtered_words','score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "717b7b77d356428d9c34ff10901d004d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@timeit\n",
    "def term_frequency(df, inputCol, outputCol, hashFeatures=None):\n",
    "    '''\n",
    "    Returns a DataFrame object containing a new row with the extracted features. \n",
    "    Passing hashed=True will return a Featured Hashed matrix.\n",
    "    \n",
    "    @params:\n",
    "        df - DataFrame\n",
    "        inputCol - name of input column from DataFrame to find features\n",
    "        outputCol - name of the column to save the features\n",
    "        hashFeatures - number of features for HashingTF, if None will perform \n",
    "            CountVectorization\n",
    "    '''\n",
    "    \n",
    "    # since the number of features was not passed perform standard CountVectorization\n",
    "    if hashFeatures is None:\n",
    "        cv = CountVectorizer(inputCol=inputCol, outputCol=outputCol)\n",
    "        feature_extractor = cv.fit(wordsFilteredDF)\n",
    "    # otherwise perform a feature extractor with \n",
    "    else:\n",
    "        feature_extractor = HashingTF(\\\n",
    "                              inputCol=inputCol, outputCol=outputCol, numFeatures=hashFeatures)\n",
    "    \n",
    "    # create a new DataFrame using either feature extraction method\n",
    "    return feature_extractor.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6737d127f3643d891ceeceeda536d6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'term_frequency' took 0.16 sec\n",
      "\n",
      "+--------------------+--------------------+\n",
      "|      filtered_words|            features|\n",
      "+--------------------+--------------------+\n",
      "|[us, family, memb...|(1024,[368,386,45...|\n",
      "|[mill's, career, ...|(1024,[102,211,22...|\n",
      "|[mine, uses, stra...|(1024,[112,120,18...|\n",
      "|[fast,, thank, you!]|(1024,[206,220,36...|\n",
      "|[guy, professiona...|(1024,[95,358,366...|\n",
      "+--------------------+--------------------+\n",
      "only showing top 5 rows"
     ]
    }
   ],
   "source": [
    "# Feature Hash the comment content\n",
    "# number of features for Feature Hash matrix, reccomended too use power of 2\n",
    "hashDF = term_frequency(\\\n",
    "    df=wordsFilteredDF, inputCol=\"filtered_words\", outputCol=\"features\", hashFeatures=1024)\n",
    "\n",
    "# Display snippet of new DataFrame\n",
    "hashDF.select('filtered_words','features').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75247c008cfb461982ca6e4808b30106",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.mllib.classification import LogisticRegressionWithLBFGS, LogisticRegressionModel, LogisticRegressionWithSGD\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "@timeit\n",
    "def logistic_regression(df, featuresCol, labelCol):\n",
    "    '''\n",
    "    Returns a DataFrame containing a column of predicted values of the labelCol.\n",
    "    Predict the output of labelCol using values in featuresCol y = rf(x).\n",
    "    \n",
    "    @params:\n",
    "        df - DataFrame\n",
    "        featuresCol - input features, x\n",
    "        labelCol - output variable, y\n",
    "    '''\n",
    "    # split the training and test data using the holdout method\n",
    "    print(df.count())\n",
    "    df = df.filter((df.score >=0) & (df.score <10))\n",
    "    print(df.show(10))\n",
    "    print(df.count())\n",
    "    (trainingData, testData) = df.randomSplit([0.8, 0.2])\n",
    "    \n",
    "    \n",
    "    # TODO: Uncomment the lines below and replace <FILL IN> with appropriate code\n",
    "    # Given hyperparameters\n",
    "    standardization = False\n",
    "    elastic_net_param = 0.8\n",
    "    reg_param = .3\n",
    "    max_iter = 10\n",
    "\n",
    "    lr = (LogisticRegression(featuresCol=featuresCol, labelCol=labelCol, regParam = reg_param, standardization = standardization, maxIter = max_iter,elasticNetParam = elastic_net_param))\n",
    "#     lr = (LogisticRegressionWithLBFGS(featuresCol=featuresCol, labelCol=labelCol, regParam = reg_param, standardization = standardization, maxIter = max_iter,elasticNetParam = elastic_net_param))\n",
    "#     model = LogisticRegressionWithLBFGS.train(trainingData, numClasses=5)\n",
    "#     print(lr.numClasses)\n",
    "#     \n",
    "    lr_model_basic = lr.fit(trainingData)\n",
    "#     lr_model_basic =LogisticRegressionWithLBFGS.train(trainingData.rdd(),numClasses=5)\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    # raise NotImplementedError()\n",
    "\n",
    "    #print('intercept: {0}'.format(lr_model_basic.interceptVector))\n",
    "#     print('length of coefficients: {0}'.format(len(lr_model_basic.coefficientMatrix)))\n",
    "#     sorted_coefficients = sorted(lr_model_basic.coefficients)[:5]\n",
    "    trainingSummary = lr_model_basic.summary\n",
    "    accuracy = trainingSummary.accuracy\n",
    "    print(accuracy)\n",
    "    # create a DataFrame contained a column with predicted values of the labelCol\n",
    "    predictions = lr_model_basic.transform(testData)\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03947fcfa7e647ffa0b259b8d64915fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "147697374\n",
      "+-------+---+--------------------+-----+--------------------+\n",
      "|     id|ups|      filtered_words|score|            features|\n",
      "+-------+---+--------------------+-----+--------------------+\n",
      "|cnas8zw|  3|[mill's, career, ...|    3|(1024,[102,211,22...|\n",
      "|cnas8zx|  1|[mine, uses, stra...|    1|(1024,[112,120,18...|\n",
      "|cnas8zz|  2|[fast,, thank, you!]|    2|(1024,[206,220,36...|\n",
      "|cnas900|  6|[guy, professiona...|    6|(1024,[95,358,366...|\n",
      "|cnas901|  1|[great, question,...|    1|(1024,[8,84,116,1...|\n",
      "|cnas902|  1|[ie-shiv-ghostbla...|    1|(1024,[27,227,360...|\n",
      "|cnas903|  1|               [:d.]|    1|  (1024,[449],[1.0])|\n",
      "|cnas905|  2|[know, describe, ...|    2|(1024,[47,57,304,...|\n",
      "|cnas906|  2|           [says, g]|    2|(1024,[34,305],[1...|\n",
      "|cnas908|  1|      [love, music!]|    1|(1024,[112,526],[...|\n",
      "+-------+---+--------------------+-----+--------------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "None\n",
      "129748976\n",
      "0.4981419606834204\n",
      "'logistic_regression' took 978.57 sec\n",
      "\n",
      "Root Mean Squared Error (RMSE) on test data = 2.07662"
     ]
    }
   ],
   "source": [
    "# train random forest regression\n",
    "predictions = logistic_regression(df=hashDF,featuresCol=\"features\",labelCol=\"score\")\n",
    "\n",
    "# compute the error\n",
    "evaluator = RegressionEvaluator(labelCol=\"score\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print (\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b015730dd6c14d65a0fe37d702f81d58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+--------------------+-----+--------------------+--------------------+--------------------+----------+\n",
      "|     id|ups|      filtered_words|score|            features|       rawPrediction|         probability|prediction|\n",
      "+-------+---+--------------------+-----+--------------------+--------------------+--------------------+----------+\n",
      "|cnas8zw|  3|[mill's, career, ...|    3|(1024,[102,211,22...|[0.04909956962601...|[0.04955318228260...|       1.0|\n",
      "|cnas902|  1|[ie-shiv-ghostbla...|    1|(1024,[27,227,360...|[0.04909956962601...|[0.04955318228260...|       1.0|\n",
      "|cnas906|  2|           [says, g]|    2|(1024,[34,305],[1...|[0.04909956962601...|[0.04955318228260...|       1.0|\n",
      "|cnas90c|  1|[enjoy, deep,, 10...|    1|(1024,[122,127,27...|[0.04909956962601...|[0.04955318228260...|       1.0|\n",
      "|cnas90k|  2|[\"hey, rocky,, wa...|    2|(1024,[19,116,241...|[0.04909956962601...|[0.04955318228260...|       1.0|\n",
      "|cnas914|  1|[like, idea,, tho...|    1|(1024,[0,27,56,88...|[0.04909956962601...|[0.04955318228260...|       1.0|\n",
      "|cnas91a|  1|[tried, turning, ...|    1|(1024,[66,733,751...|[0.04909956962601...|[0.04955318228260...|       1.0|\n",
      "|cnas91c|  1|[dodge, rampage,,...|    1|(1024,[57,68,71,1...|[0.04909956962601...|[0.04955318228260...|       1.0|\n",
      "|cnas91j|  1|[totally, agree,,...|    1|(1024,[0,25,26,39...|[0.04909956962601...|[0.04955318228260...|       1.0|\n",
      "|cnas91k|  1|[please, take, mo...|    1|(1024,[343,521,58...|[0.04909956962601...|[0.04955318228260...|       1.0|\n",
      "+-------+---+--------------------+-----+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 10 rows"
     ]
    }
   ],
   "source": [
    "predictions.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 2
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
